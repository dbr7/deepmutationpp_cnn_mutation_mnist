{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import statsmodels.stats.proportion as smp\n",
    "\n",
    "HOME_DIR = '/home/DC_replication'\n",
    "OUTPUT_DIR = './output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_subject = 'mnist'\n",
    "total_model_num = 20"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ki files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "kis_dmpp, kis_dc = {}, {}\n",
    "\n",
    "\n",
    "# import ki files (dm++)\n",
    "dmpp_ki_dir = f'{OUTPUT_DIR}/ki/'    \n",
    "ki_files = os.listdir(dmpp_ki_dir)\n",
    "for ki_file in ki_files:\n",
    "    if ki_file.endswith('ki.npy'):\n",
    "        ki = np.load(os.path.join(dmpp_ki_dir, ki_file))\n",
    "        kis_dmpp[ki_file] = ki\n",
    "\n",
    "# import ki files (dc)\n",
    "dc_ki_dir = f'{HOME_DIR}/Data/inputs_killability/{target_subject}'    \n",
    "for ki_file in os.listdir(dc_ki_dir):\n",
    "    if ki_file.startswith(target_subject) and ki_file.endswith('_ki.npy'):\n",
    "        ki = np.load(os.path.join(dc_ki_dir, ki_file))        \n",
    "        kis_dc[ki_file] = ki\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 60000) 92\n",
      "(20, 60000) 218\n"
     ]
    }
   ],
   "source": [
    "print(kis_dmpp['mnist_op:4_mutant:11_ki.npy'].shape, len(kis_dmpp))\n",
    "print(kis_dc['mnist_change_epochs_mutated0_MP_False_8_ki.npy'].shape, len(kis_dc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate_unstable_inputs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confidence_intervals():\n",
    "    confidence_intervals = []\n",
    "\n",
    "    for i in range(0, total_model_num+1):\n",
    "        (low, high) = smp.proportion_confint(i, total_model_num, alpha=0.10, method='wilson')\n",
    "        confidence_intervals.append((low, high))\n",
    "\n",
    "    return confidence_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 218/218 [49:19<00:00, 13.58s/it]\n"
     ]
    }
   ],
   "source": [
    "confidence_intervals = get_confidence_intervals()\n",
    "input_dict = dict()\n",
    "input_dict_file = os.path.join(OUTPUT_DIR, \"unstable_input_dict.pickle\")\n",
    "\n",
    "if not os.path.exists(input_dict_file):\n",
    "    for mut1, ki1 in tqdm(kis_dc.items()):\n",
    "        killing_probabilities1 = np.sum(ki1, axis=0) / len(ki1)\n",
    "        input_dict[mut1] = {}\n",
    "        for mut2, ki2 in kis_dmpp.items():\n",
    "            overlap_num = 0\n",
    "            indices_to_delete = []\n",
    "            killing_probabilities2 = np.sum(ki2, axis=0) / len(ki2)\n",
    "\n",
    "            for i in range(0, len(killing_probabilities1)):\n",
    "                num_killed1 = int(killing_probabilities1[i] * total_model_num)\n",
    "                num_killed2 = int(killing_probabilities2[i] * total_model_num)\n",
    "\n",
    "                interval1 = confidence_intervals[num_killed1]\n",
    "                interval2 = confidence_intervals[num_killed2]\n",
    "\n",
    "                if interval1[0] <= interval2[0] <= interval1[1] or interval2[0] <= interval1[0] <= interval2[1]:\n",
    "                    indices_to_delete.append(i)\n",
    "                    overlap_num = overlap_num + 1\n",
    "\n",
    "            input_dict[mut1][mut2] = indices_to_delete\n",
    "\n",
    "    with open(input_dict_file, 'wb') as f:\n",
    "        pickle.dump(input_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [49:29<00:00, 32.27s/it]\n"
     ]
    }
   ],
   "source": [
    "input_dict = dict()\n",
    "input_dict_file = os.path.join(OUTPUT_DIR, \"unstable_input_dict2.pickle\")\n",
    "\n",
    "if not os.path.exists(input_dict_file):\n",
    "    for mut1, ki1 in tqdm(kis_dmpp.items()):\n",
    "        killing_probabilities1 = np.sum(ki1, axis=0) / len(ki1)\n",
    "        input_dict[mut1] = {}\n",
    "        for mut2, ki2 in kis_dc.items():\n",
    "            overlap_num = 0\n",
    "            indices_to_delete = []\n",
    "            killing_probabilities2 = np.sum(ki2, axis=0) / len(ki2)\n",
    "\n",
    "            for i in range(0, len(killing_probabilities1)):\n",
    "                num_killed1 = int(killing_probabilities1[i] * total_model_num)\n",
    "                num_killed2 = int(killing_probabilities2[i] * total_model_num)\n",
    "\n",
    "                interval1 = confidence_intervals[num_killed1]\n",
    "                interval2 = confidence_intervals[num_killed2]\n",
    "\n",
    "                if interval1[0] <= interval2[0] <= interval1[1] or interval2[0] <= interval1[0] <= interval2[1]:\n",
    "                    indices_to_delete.append(i)\n",
    "                    overlap_num = overlap_num + 1\n",
    "\n",
    "            input_dict[mut1][mut2] = indices_to_delete\n",
    "\n",
    "    with open(input_dict_file, 'wb') as f:\n",
    "        pickle.dump(input_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analyse_redundancy (to see whether DC mutants subsume DM++ mutants)\n",
    "Here I used \"unstable_input_dict\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict_file = os.path.join(OUTPUT_DIR, \"unstable_input_dict.pickle\")\n",
    "with open(input_dict_file, 'rb') as f:\n",
    "    unstable_inputs_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "g = nx.DiGraph()\n",
    "threshold = 100\n",
    "\n",
    "for mut1, ki1 in kis_dc.items():\n",
    "    killing_probabilities1 = np.sum(ki1, axis=0) / len(ki1)\n",
    "    if mut1 not in g:\n",
    "        g.add_node(mut1)\n",
    "\n",
    "    for mut2, ki2 in kis_dmpp.items():\n",
    "        if mut2 not in unstable_inputs_dict[mut1]:\n",
    "            continue\n",
    "        killing_probabilities2 = np.sum(ki2, axis=0) / len(ki2)\n",
    "        indices_to_delete = unstable_inputs_dict[mut1][mut2]\n",
    "\n",
    "        if len(indices_to_delete) < len(killing_probabilities1):\n",
    "            killing_probabilities1_copy = np.delete(killing_probabilities1, indices_to_delete)\n",
    "            killing_probabilities2_copy = np.delete(killing_probabilities2, indices_to_delete)\n",
    "\n",
    "            if len(killing_probabilities1_copy) != 0 and len(killing_probabilities2_copy) != 0:\n",
    "                comparison_array = np.less_equal(killing_probabilities1_copy, killing_probabilities2_copy)\n",
    "                num_true = len(np.argwhere(comparison_array == True))\n",
    "                # print(num_true)\n",
    "                sc_low, sc_high = smp.proportion_confint(num_true, len(killing_probabilities1_copy), alpha=0.10, method='wilson')\n",
    "                error = (sc_high - sc_low) / 2\n",
    "\n",
    "                if error < 0.05 and num_true >= (threshold / 100) * len(killing_probabilities1_copy):\n",
    "                    g.add_edge(mut1, mut2)\n",
    "\n",
    "nodes = np.sort(g.nodes())\n",
    "\n",
    "redundant_nodes = []\n",
    "non_redundant_nodes = []\n",
    "for node in nodes:\n",
    "    if g.in_degree(node) == 0:\n",
    "        non_redundant_nodes.append(str(node))\n",
    "    else:\n",
    "        redundant_nodes.append(str(node))\n",
    "\n",
    "print(len(non_redundant_nodes))\n",
    "print(len(redundant_nodes))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analyse_redundancy (to see whether DM++ mutants subsume DC mutants)\n",
    "Here I used \"unstable_input_dict2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict_file = os.path.join(OUTPUT_DIR, \"unstable_input_dict2.pickle\")\n",
    "with open(input_dict_file, 'rb') as f:\n",
    "    unstable_inputs_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "208\n"
     ]
    }
   ],
   "source": [
    "g = nx.DiGraph()\n",
    "threshold = 100\n",
    "\n",
    "for mut1, ki1 in kis_dmpp.items():\n",
    "    killing_probabilities1 = np.sum(ki1, axis=0) / len(ki1)\n",
    "    if mut1 not in g:\n",
    "        g.add_node(mut1)\n",
    "\n",
    "    for mut2, ki2 in kis_dc.items():\n",
    "        if mut2 not in unstable_inputs_dict[mut1]:\n",
    "            continue\n",
    "        killing_probabilities2 = np.sum(ki2, axis=0) / len(ki2)\n",
    "        indices_to_delete = unstable_inputs_dict[mut1][mut2]\n",
    "\n",
    "        if len(indices_to_delete) < len(killing_probabilities1):\n",
    "            killing_probabilities1_copy = np.delete(killing_probabilities1, indices_to_delete)\n",
    "            killing_probabilities2_copy = np.delete(killing_probabilities2, indices_to_delete)\n",
    "\n",
    "            if len(killing_probabilities1_copy) != 0 and len(killing_probabilities2_copy) != 0:\n",
    "                comparison_array = np.less_equal(killing_probabilities1_copy, killing_probabilities2_copy)\n",
    "                num_true = len(np.argwhere(comparison_array == True))                \n",
    "                sc_low, sc_high = smp.proportion_confint(num_true, len(killing_probabilities1_copy), alpha=0.10, method='wilson')\n",
    "                error = (sc_high - sc_low) / 2\n",
    "\n",
    "                if error < 0.05 and num_true >= (threshold / 100) * len(killing_probabilities1_copy):\n",
    "                    g.add_edge(mut1, mut2)\n",
    "\n",
    "nodes = np.sort(g.nodes())\n",
    "\n",
    "redundant_nodes = []\n",
    "non_redundant_nodes = []\n",
    "for node in nodes:\n",
    "    if g.in_degree(node) == 0:\n",
    "        non_redundant_nodes.append(str(node))\n",
    "    else:\n",
    "        redundant_nodes.append(str(node))\n",
    "\n",
    "print(len(non_redundant_nodes))\n",
    "print(len(redundant_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_add_noise_mutated0_MP_100_ki.npy 14\n",
      "mnist_add_noise_mutated0_MP_25.0_ki.npy 4\n",
      "mnist_add_noise_mutated0_MP_31.25_ki.npy 5\n",
      "mnist_add_noise_mutated0_MP_34.38_ki.npy 6\n",
      "mnist_add_noise_mutated0_MP_37.5_ki.npy 4\n",
      "mnist_add_noise_mutated0_MP_40.62_ki.npy 5\n",
      "mnist_add_noise_mutated0_MP_43.75_ki.npy 7\n",
      "mnist_add_noise_mutated0_MP_46.88_ki.npy 12\n",
      "mnist_add_noise_mutated0_MP_50.0_ki.npy 11\n",
      "mnist_add_noise_mutated0_MP_56.25_ki.npy 9\n",
      "mnist_add_noise_mutated0_MP_59.38_ki.npy 8\n",
      "mnist_add_noise_mutated0_MP_62.5_ki.npy 12\n",
      "mnist_add_noise_mutated0_MP_68.75_ki.npy 14\n",
      "mnist_add_noise_mutated0_MP_71.88_ki.npy 13\n",
      "mnist_add_noise_mutated0_MP_75.0_ki.npy 12\n",
      "mnist_add_noise_mutated0_MP_87.5_ki.npy 17\n",
      "mnist_add_noise_mutated0_MP_90.62_ki.npy 17\n",
      "mnist_add_noise_mutated0_MP_93.75_ki.npy 17\n",
      "mnist_add_noise_mutated0_MP_96.88_ki.npy 13\n",
      "mnist_add_weights_regularisation_mutated0_MP_l1_0_ki.npy 13\n",
      "mnist_add_weights_regularisation_mutated0_MP_l1_l2_0_ki.npy 14\n",
      "mnist_add_weights_regularisation_mutated0_MP_l2_0_ki.npy 12\n",
      "mnist_change_activation_function_mutated0_MP_elu_6_ki.npy 17\n",
      "mnist_change_activation_function_mutated0_MP_exponential_6_ki.npy 15\n",
      "mnist_change_activation_function_mutated0_MP_hard_sigmoid_6_ki.npy 20\n",
      "mnist_change_activation_function_mutated0_MP_linear_6_ki.npy 5\n",
      "mnist_change_activation_function_mutated0_MP_relu_6_ki.npy 1\n",
      "mnist_change_activation_function_mutated0_MP_sigmoid_6_ki.npy 19\n",
      "mnist_change_activation_function_mutated0_MP_softmax_6_ki.npy 11\n",
      "mnist_change_activation_function_mutated0_MP_softplus_6_ki.npy 14\n",
      "mnist_change_activation_function_mutated0_MP_softsign_6_ki.npy 7\n",
      "mnist_change_activation_function_mutated0_MP_tanh_6_ki.npy 7\n",
      "mnist_change_batch_size_mutated0_MP_256_256_ki.npy 3\n",
      "mnist_change_batch_size_mutated0_MP_32_32_ki.npy 10\n",
      "mnist_change_batch_size_mutated0_MP_512_512_ki.npy 22\n",
      "mnist_change_batch_size_mutated0_MP_64_64_ki.npy 15\n",
      "mnist_change_dropout_rate_mutated0_MP_0.125_0.125_3_ki.npy 1\n",
      "mnist_change_dropout_rate_mutated0_MP_0.125_0.125_6_ki.npy 1\n",
      "mnist_change_dropout_rate_mutated0_MP_0.25_0.25_3_ki.npy 1\n",
      "mnist_change_dropout_rate_mutated0_MP_0.25_0.25_6_ki.npy 1\n",
      "mnist_change_dropout_rate_mutated0_MP_0.75_0.75_3_ki.npy 1\n",
      "mnist_change_dropout_rate_mutated0_MP_0.75_0.75_6_ki.npy 4\n",
      "mnist_change_dropout_rate_mutated0_MP_1.0_1.0_3_ki.npy 3\n",
      "mnist_change_dropout_rate_mutated0_MP_1.0_1.0_6_ki.npy 4\n",
      "mnist_change_dropout_rate_mutated0_MP_3_ki.npy 1\n",
      "mnist_change_epochs_mutated0_MP_10_ki.npy 12\n",
      "mnist_change_epochs_mutated0_MP_11_ki.npy 5\n",
      "mnist_change_epochs_mutated0_MP_1_ki.npy 31\n",
      "mnist_change_epochs_mutated0_MP_6_ki.npy 19\n",
      "mnist_change_epochs_mutated0_MP_7_ki.npy 14\n",
      "mnist_change_epochs_mutated0_MP_8_ki.npy 12\n",
      "mnist_change_epochs_mutated0_MP_9_ki.npy 13\n",
      "mnist_change_epochs_mutated0_MP_False_10_ki.npy 10\n",
      "mnist_change_epochs_mutated0_MP_False_11_ki.npy 3\n",
      "mnist_change_epochs_mutated0_MP_False_1_ki.npy 27\n",
      "mnist_change_epochs_mutated0_MP_False_2_ki.npy 27\n",
      "mnist_change_epochs_mutated0_MP_False_3_ki.npy 26\n",
      "mnist_change_epochs_mutated0_MP_False_4_ki.npy 24\n",
      "mnist_change_epochs_mutated0_MP_False_5_ki.npy 22\n",
      "mnist_change_epochs_mutated0_MP_False_6_ki.npy 21\n",
      "mnist_change_epochs_mutated0_MP_False_7_ki.npy 15\n",
      "mnist_change_epochs_mutated0_MP_False_8_ki.npy 17\n",
      "mnist_change_epochs_mutated0_MP_False_9_ki.npy 14\n",
      "mnist_change_label_mutated0_MP_100_ki.npy 6\n",
      "mnist_change_label_mutated0_MP_12.5_ki.npy 10\n",
      "mnist_change_label_mutated0_MP_15.62_ki.npy 6\n",
      "mnist_change_label_mutated0_MP_18.75_ki.npy 7\n",
      "mnist_change_label_mutated0_MP_21.88_ki.npy 6\n",
      "mnist_change_label_mutated0_MP_25.0_ki.npy 8\n",
      "mnist_change_label_mutated0_MP_28.12_ki.npy 2\n",
      "mnist_change_label_mutated0_MP_3.12_ki.npy 8\n",
      "mnist_change_label_mutated0_MP_31.25_ki.npy 8\n",
      "mnist_change_label_mutated0_MP_37.5_ki.npy 10\n",
      "mnist_change_label_mutated0_MP_43.75_ki.npy 8\n",
      "mnist_change_label_mutated0_MP_46.88_ki.npy 7\n",
      "mnist_change_label_mutated0_MP_50.0_ki.npy 6\n",
      "mnist_change_label_mutated0_MP_56.25_ki.npy 7\n",
      "mnist_change_label_mutated0_MP_59.38_ki.npy 7\n",
      "mnist_change_label_mutated0_MP_6.25_ki.npy 10\n",
      "mnist_change_label_mutated0_MP_62.5_ki.npy 6\n",
      "mnist_change_label_mutated0_MP_75.0_ki.npy 7\n",
      "mnist_change_label_mutated0_MP_81.25_ki.npy 6\n",
      "mnist_change_label_mutated0_MP_84.38_ki.npy 7\n",
      "mnist_change_label_mutated0_MP_87.5_ki.npy 5\n",
      "mnist_change_label_mutated0_MP_9.38_ki.npy 10\n",
      "mnist_change_label_mutated0_MP_93.75_ki.npy 3\n",
      "mnist_change_learning_rate_mutated0_MP_False_0.001_ki.npy 5\n",
      "mnist_change_learning_rate_mutated0_MP_False_0.064_ki.npy 6\n",
      "mnist_change_learning_rate_mutated0_MP_False_0.126_ki.npy 9\n",
      "mnist_change_learning_rate_mutated0_MP_False_0.189_ki.npy 14\n",
      "mnist_change_learning_rate_mutated0_MP_False_0.251_ki.npy 11\n",
      "mnist_change_learning_rate_mutated0_MP_False_0.314_ki.npy 14\n",
      "mnist_change_learning_rate_mutated0_MP_False_0.376_ki.npy 14\n",
      "mnist_change_learning_rate_mutated0_MP_False_0.438_ki.npy 13\n",
      "mnist_change_learning_rate_mutated0_MP_False_0.562_ki.npy 11\n",
      "mnist_change_learning_rate_mutated0_MP_False_0.56_ki.npy 12\n",
      "mnist_change_learning_rate_mutated0_MP_False_0.5_ki.npy 15\n",
      "mnist_change_learning_rate_mutated0_MP_False_0.625_ki.npy 9\n",
      "mnist_change_learning_rate_mutated0_MP_False_0.62_ki.npy 9\n",
      "mnist_change_learning_rate_mutated0_MP_False_0.688_ki.npy 14\n",
      "mnist_change_learning_rate_mutated0_MP_False_0.69_ki.npy 10\n",
      "mnist_change_learning_rate_mutated0_MP_False_0.75_ki.npy 5\n",
      "mnist_change_learning_rate_mutated0_MP_False_0.812_ki.npy 7\n",
      "mnist_change_learning_rate_mutated0_MP_False_0.81_ki.npy 9\n",
      "mnist_change_learning_rate_mutated0_MP_False_0.875_ki.npy 6\n",
      "mnist_change_learning_rate_mutated0_MP_False_0.88_ki.npy 7\n",
      "mnist_change_learning_rate_mutated0_MP_False_0.938_ki.npy 2\n",
      "mnist_change_loss_function_mutated0_MP_binary_crossentropy_ki.npy 6\n",
      "mnist_change_loss_function_mutated0_MP_categorical_crossentropy_ki.npy 3\n",
      "mnist_change_loss_function_mutated0_MP_categorical_hinge_ki.npy 19\n",
      "mnist_change_loss_function_mutated0_MP_hinge_ki.npy 6\n",
      "mnist_change_loss_function_mutated0_MP_huber_loss_ki.npy 3\n",
      "mnist_change_loss_function_mutated0_MP_kullback_leibler_divergence_ki.npy 1\n",
      "mnist_change_loss_function_mutated0_MP_logcosh_ki.npy 5\n",
      "mnist_change_loss_function_mutated0_MP_mean_absolute_error_ki.npy 6\n",
      "mnist_change_loss_function_mutated0_MP_mean_absolute_percentage_error_ki.npy 11\n",
      "mnist_change_loss_function_mutated0_MP_mean_squared_error_ki.npy 6\n",
      "mnist_change_loss_function_mutated0_MP_mean_squared_logarithmic_error_ki.npy 3\n",
      "mnist_change_loss_function_mutated0_MP_poisson_ki.npy 9\n",
      "mnist_change_loss_function_mutated0_MP_sparse_categorical_crossentropy_ki.npy 3\n",
      "mnist_change_loss_function_mutated0_MP_squared_hinge_ki.npy 12\n",
      "mnist_change_optimisation_function_mutated0_MP_adagrad_ki.npy 4\n",
      "mnist_change_optimisation_function_mutated0_MP_rmsprop_ki.npy 18\n",
      "mnist_change_optimisation_function_mutated0_MP_sgd_ki.npy 3\n",
      "mnist_change_weights_initialisation_mutated0_MP_constant_0_ki.npy 20\n",
      "mnist_change_weights_initialisation_mutated0_MP_glorot_normal_0_ki.npy 1\n",
      "mnist_change_weights_initialisation_mutated0_MP_glorot_uniform_0_ki.npy 3\n",
      "mnist_change_weights_initialisation_mutated0_MP_ones_0_ki.npy 5\n",
      "mnist_change_weights_initialisation_mutated0_MP_random_normal_0_ki.npy 2\n",
      "mnist_change_weights_initialisation_mutated0_MP_random_uniform_0_ki.npy 9\n",
      "mnist_change_weights_initialisation_mutated0_MP_truncated_normal_0_ki.npy 3\n",
      "mnist_change_weights_initialisation_mutated0_MP_zeros_0_ki.npy 20\n",
      "mnist_change_weights_initialisation_mutated0_MP_zeros_1_ki.npy 20\n",
      "mnist_delete_training_data_mutated0_MP_12.38_ki.npy 14\n",
      "mnist_delete_training_data_mutated0_MP_15.48_ki.npy 9\n",
      "mnist_delete_training_data_mutated0_MP_18.57_ki.npy 14\n",
      "mnist_delete_training_data_mutated0_MP_21.66_ki.npy 14\n",
      "mnist_delete_training_data_mutated0_MP_24.75_ki.npy 16\n",
      "mnist_delete_training_data_mutated0_MP_27.84_ki.npy 25\n",
      "mnist_delete_training_data_mutated0_MP_3.1_ki.npy 3\n",
      "mnist_delete_training_data_mutated0_MP_30.93_ki.npy 22\n",
      "mnist_delete_training_data_mutated0_MP_34.02_ki.npy 29\n",
      "mnist_delete_training_data_mutated0_MP_37.12_ki.npy 22\n",
      "mnist_delete_training_data_mutated0_MP_40.22_ki.npy 29\n",
      "mnist_delete_training_data_mutated0_MP_43.31_ki.npy 30\n",
      "mnist_delete_training_data_mutated0_MP_46.41_ki.npy 27\n",
      "mnist_delete_training_data_mutated0_MP_49.5_ki.npy 33\n",
      "mnist_delete_training_data_mutated0_MP_52.59_ki.npy 33\n",
      "mnist_delete_training_data_mutated0_MP_55.69_ki.npy 32\n",
      "mnist_delete_training_data_mutated0_MP_58.78_ki.npy 35\n",
      "mnist_delete_training_data_mutated0_MP_6.19_ki.npy 7\n",
      "mnist_delete_training_data_mutated0_MP_61.88_ki.npy 32\n",
      "mnist_delete_training_data_mutated0_MP_64.97_ki.npy 31\n",
      "mnist_delete_training_data_mutated0_MP_68.06_ki.npy 33\n",
      "mnist_delete_training_data_mutated0_MP_71.16_ki.npy 29\n",
      "mnist_delete_training_data_mutated0_MP_74.25_ki.npy 35\n",
      "mnist_delete_training_data_mutated0_MP_77.34_ki.npy 35\n",
      "mnist_delete_training_data_mutated0_MP_80.44_ki.npy 33\n",
      "mnist_delete_training_data_mutated0_MP_83.53_ki.npy 31\n",
      "mnist_delete_training_data_mutated0_MP_86.62_ki.npy 35\n",
      "mnist_delete_training_data_mutated0_MP_89.72_ki.npy 29\n",
      "mnist_delete_training_data_mutated0_MP_9.29_ki.npy 12\n",
      "mnist_delete_training_data_mutated0_MP_92.81_ki.npy 30\n",
      "mnist_delete_training_data_mutated0_MP_95.91_ki.npy 58\n",
      "mnist_delete_training_data_mutated0_MP_99_ki.npy 23\n",
      "mnist_disable_batching_mutated0_MP_ki.npy 13\n",
      "mnist_make_output_classes_overlap_mutated0_MP_100_ki.npy 5\n",
      "mnist_make_output_classes_overlap_mutated0_MP_12.5_ki.npy 6\n",
      "mnist_make_output_classes_overlap_mutated0_MP_18.75_ki.npy 8\n",
      "mnist_make_output_classes_overlap_mutated0_MP_21.88_ki.npy 8\n",
      "mnist_make_output_classes_overlap_mutated0_MP_25.0_ki.npy 6\n",
      "mnist_make_output_classes_overlap_mutated0_MP_50.0_ki.npy 8\n",
      "mnist_make_output_classes_overlap_mutated0_MP_75.0_ki.npy 9\n",
      "mnist_make_output_classes_overlap_mutated0_MP_87.5_ki.npy 6\n",
      "mnist_make_output_classes_overlap_mutated0_MP_93.75_ki.npy 11\n",
      "mnist_make_output_classes_overlap_mutated0_MP_96.88_ki.npy 8\n",
      "mnist_remove_activation_function_mutated0_MP_0_ki.npy 5\n",
      "mnist_remove_activation_function_mutated0_MP_5_ki.npy 3\n",
      "mnist_remove_activation_function_mutated0_MP_7_ki.npy 57\n",
      "mnist_remove_bias_mutated0_MP_0_ki.npy 1\n",
      "mnist_remove_bias_mutated0_MP_1_ki.npy 2\n",
      "mnist_remove_bias_mutated0_MP_5_ki.npy 5\n",
      "mnist_remove_bias_mutated0_MP_7_ki.npy 1\n",
      "mnist_remove_validation_set_mutated0_MP_ki.npy 1\n",
      "mnist_unbalance_train_data_mutated0_MP_100_ki.npy 4\n",
      "mnist_unbalance_train_data_mutated0_MP_12.5_ki.npy 10\n",
      "mnist_unbalance_train_data_mutated0_MP_18.75_ki.npy 8\n",
      "mnist_unbalance_train_data_mutated0_MP_21.88_ki.npy 5\n",
      "mnist_unbalance_train_data_mutated0_MP_25.0_ki.npy 7\n",
      "mnist_unbalance_train_data_mutated0_MP_31.25_ki.npy 6\n",
      "mnist_unbalance_train_data_mutated0_MP_34.38_ki.npy 8\n",
      "mnist_unbalance_train_data_mutated0_MP_37.5_ki.npy 9\n",
      "mnist_unbalance_train_data_mutated0_MP_43.75_ki.npy 12\n",
      "mnist_unbalance_train_data_mutated0_MP_46.88_ki.npy 13\n",
      "mnist_unbalance_train_data_mutated0_MP_50.0_ki.npy 9\n",
      "mnist_unbalance_train_data_mutated0_MP_6.25_ki.npy 3\n",
      "mnist_unbalance_train_data_mutated0_MP_62.5_ki.npy 5\n",
      "mnist_unbalance_train_data_mutated0_MP_68.75_ki.npy 6\n",
      "mnist_unbalance_train_data_mutated0_MP_71.88_ki.npy 10\n",
      "mnist_unbalance_train_data_mutated0_MP_75.0_ki.npy 4\n",
      "mnist_unbalance_train_data_mutated0_MP_78.12_ki.npy 8\n",
      "mnist_unbalance_train_data_mutated0_MP_81.25_ki.npy 8\n",
      "mnist_unbalance_train_data_mutated0_MP_84.38_ki.npy 8\n",
      "mnist_unbalance_train_data_mutated0_MP_87.5_ki.npy 7\n",
      "mnist_unbalance_train_data_mutated0_MP_9.38_ki.npy 5\n",
      "mnist_unbalance_train_data_mutated0_MP_90.62_ki.npy 9\n",
      "mnist_unbalance_train_data_mutated0_MP_93.75_ki.npy 6\n",
      "mnist_unbalance_train_data_mutated0_MP_96.88_ki.npy 4\n"
     ]
    }
   ],
   "source": [
    "for node in nodes:\n",
    "    if g.in_degree(node) != 0:\n",
    "        print(node, g.in_degree(node))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cheking one example mutant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subsuming:  mnist_op:0_mutant:1_ki.npy\n",
      "22 0.4 0.0\n",
      "48 1.0 0.0\n",
      "54 0.95 0.05\n",
      "154 0.85 0.0\n",
      "160 0.6 0.0\n",
      "172 0.9 0.05\n",
      "240 0.3 0.0\n",
      "264 1.0 0.0\n",
      "282 0.8 0.0\n",
      "304 1.0 0.0\n",
      "346 0.95 0.0\n",
      "362 0.25 0.0\n",
      "404 1.0 0.0\n",
      "418 0.75 0.05\n",
      "424 0.5 0.0\n",
      "456 0.3 0.0\n",
      "482 1.0 0.0\n",
      "485 0.3 0.0\n",
      "517 0.9 0.0\n",
      "528 0.85 0.0\n",
      "589 0.35 0.0\n",
      "602 0.35 0.0\n",
      "626 0.7 0.0\n",
      "631 0.25 0.0\n",
      "641 0.35 0.0\n",
      "704 0.8 0.0\n",
      "720 1.0 0.0\n",
      "784 0.35 0.0\n",
      "788 0.95 0.05\n",
      "792 0.85 0.0\n",
      "864 0.85 0.0\n",
      "902 0.35 0.0\n",
      "974 0.5 0.0\n",
      "1066 0.5 0.0\n",
      "1116 0.3 0.0\n",
      "1120 0.9 0.0\n",
      "1138 0.9 0.0\n",
      "1207 0.45 0.0\n",
      "1214 0.45 0.0\n",
      "1219 0.35 0.0\n",
      "1239 0.85 0.0\n",
      "1282 0.9 0.0\n",
      "1316 0.25 0.0\n",
      "1352 1.0 0.15\n",
      "1360 0.55 0.0\n",
      "1364 0.9 0.0\n",
      "1518 0.4 0.0\n",
      "1522 0.85 0.0\n",
      "1552 0.6 0.0\n",
      "1598 0.95 0.0\n",
      "1622 0.45 0.0\n",
      "1674 0.95 0.0\n",
      "1683 0.6 0.0\n",
      "1758 0.75 0.0\n",
      "1804 0.55 0.0\n",
      "1875 0.9 0.0\n",
      "1914 0.5 0.0\n",
      "1925 0.3 0.0\n",
      "1940 0.7 0.05\n",
      "1948 0.85 0.05\n",
      "1968 0.95 0.0\n",
      "2030 0.75 0.0\n",
      "2141 0.25 0.0\n",
      "2150 0.7 0.0\n",
      "2194 0.25 0.0\n",
      "2231 0.7 0.0\n",
      "2302 0.85 0.0\n",
      "2385 0.6 0.0\n",
      "2421 0.35 0.0\n",
      "2425 0.55 0.0\n",
      "2426 0.25 0.0\n",
      "2438 0.8 0.0\n",
      "2593 0.5 0.0\n",
      "2598 0.35 0.0\n",
      "2600 0.9 0.0\n",
      "2636 0.3 0.0\n",
      "2682 0.85 0.0\n",
      "2728 1.0 0.0\n",
      "2763 0.35 0.0\n",
      "2764 0.9 0.0\n",
      "2779 0.75 0.0\n",
      "2781 0.75 0.0\n",
      "2795 0.25 0.0\n",
      "2798 0.25 0.0\n",
      "2815 0.85 0.0\n",
      "2845 0.65 0.0\n",
      "2901 0.45 0.05\n",
      "2934 0.35 0.0\n",
      "2956 0.25 0.0\n",
      "2958 0.6 0.0\n",
      "3000 0.3 0.0\n",
      "3002 0.35 0.0\n",
      "3026 0.45 0.0\n",
      "3027 0.6 0.0\n",
      "3030 0.95 0.0\n",
      "3044 0.4 0.0\n",
      "3094 0.95 0.0\n",
      "3095 0.7 0.0\n",
      "3146 0.4 0.0\n",
      "3168 0.8 0.0\n",
      "3254 0.25 0.0\n",
      "3273 0.4 0.0\n",
      "3355 0.25 0.0\n",
      "3374 0.85 0.0\n",
      "3382 0.75 0.0\n",
      "3407 0.25 0.0\n",
      "3425 0.35 0.0\n",
      "3432 0.8 0.1\n",
      "3447 0.7 0.0\n",
      "3508 0.7 0.0\n",
      "3510 0.7 0.1\n",
      "3512 0.9 0.0\n",
      "3517 0.35 0.0\n",
      "3570 0.9 0.0\n",
      "3594 0.9 0.0\n",
      "3662 0.95 0.05\n",
      "3692 0.35 0.0\n",
      "3730 1.0 0.0\n",
      "3742 0.75 0.0\n",
      "3744 0.55 0.0\n",
      "3760 0.25 0.0\n",
      "3762 0.9 0.05\n",
      "3770 0.3 0.0\n",
      "3827 0.5 0.0\n",
      "3842 0.25 0.0\n",
      "3931 0.4 0.0\n",
      "3982 0.45 0.0\n",
      "3986 0.7 0.0\n",
      "3998 0.8 0.0\n",
      "4050 1.0 0.0\n",
      "4058 0.9 0.0\n",
      "4103 0.75 0.0\n",
      "4122 0.9 0.05\n",
      "4139 0.5 0.0\n",
      "4151 0.9 0.0\n",
      "4158 0.75 0.0\n",
      "4213 0.7 0.0\n",
      "4253 1.0 0.0\n",
      "4258 0.55 0.0\n",
      "4272 0.25 0.0\n",
      "4315 0.45 0.0\n",
      "4329 0.5 0.0\n",
      "4362 0.95 0.0\n",
      "4368 0.25 0.0\n",
      "4434 0.4 0.0\n",
      "4459 1.0 0.0\n",
      "4468 0.35 0.0\n",
      "4544 0.65 0.0\n",
      "4578 0.45 0.0\n",
      "4634 0.95 0.0\n",
      "4678 0.3 0.0\n",
      "4689 0.75 0.0\n",
      "4690 0.25 0.0\n",
      "4692 1.0 0.05\n",
      "4754 0.35 0.0\n",
      "4834 0.9 0.05\n",
      "4860 0.8 0.0\n",
      "4873 0.85 0.0\n",
      "4887 0.65 0.0\n",
      "4909 0.3 0.0\n",
      "4968 1.0 0.0\n",
      "5024 0.55 0.0\n",
      "5042 0.85 0.0\n",
      "5063 0.25 0.0\n",
      "5136 0.9 0.0\n",
      "5163 0.65 0.0\n",
      "5170 0.4 0.0\n",
      "5208 0.35 0.0\n",
      "5248 0.3 0.0\n",
      "5316 0.75 0.0\n",
      "5338 0.95 0.0\n",
      "5350 0.45 0.0\n",
      "5360 0.85 0.0\n",
      "5372 0.4 0.0\n",
      "5390 0.75 0.0\n",
      "5394 0.35 0.0\n",
      "5404 0.75 0.0\n",
      "5430 0.95 0.0\n",
      "5454 0.5 0.0\n",
      "5478 0.3 0.0\n",
      "5536 1.0 0.0\n",
      "5538 0.9 0.0\n",
      "5548 0.95 0.0\n",
      "5572 0.35 0.0\n",
      "5628 0.3 0.0\n",
      "5664 0.6 0.0\n",
      "5704 0.7 0.1\n",
      "5718 0.85 0.05\n",
      "5740 1.0 0.0\n",
      "5794 0.6 0.0\n",
      "5806 0.85 0.0\n",
      "5868 1.0 0.0\n",
      "5874 0.25 0.0\n",
      "5896 0.8 0.05\n",
      "5898 0.45 0.0\n",
      "5916 0.55 0.0\n",
      "5964 0.5 0.0\n",
      "5972 0.75 0.0\n",
      "6036 0.5 0.0\n",
      "6066 0.9 0.05\n",
      "6100 0.5 0.0\n",
      "6129 0.25 0.0\n",
      "6152 0.55 0.0\n",
      "6156 0.3 0.0\n",
      "6162 0.8 0.0\n",
      "6174 0.6 0.0\n",
      "6272 0.45 0.0\n",
      "6345 0.4 0.0\n",
      "6368 0.65 0.0\n",
      "6418 0.25 0.0\n",
      "6498 0.75 0.05\n",
      "6582 0.95 0.0\n",
      "6604 0.5 0.0\n",
      "6606 1.0 0.0\n",
      "6661 0.55 0.0\n",
      "6668 0.75 0.0\n",
      "6694 0.5 0.0\n",
      "6746 0.9 0.0\n",
      "6769 0.25 0.0\n",
      "6808 1.0 0.0\n",
      "6816 0.4 0.0\n",
      "6838 0.45 0.0\n",
      "6905 0.95 0.0\n",
      "6918 1.0 0.0\n",
      "6934 0.95 0.0\n",
      "6942 0.7 0.0\n",
      "6962 0.9 0.0\n",
      "6976 0.55 0.0\n",
      "7000 0.75 0.0\n",
      "7006 0.95 0.0\n",
      "7136 1.0 0.0\n",
      "7168 0.85 0.0\n",
      "7182 0.55 0.0\n",
      "7184 0.3 0.0\n",
      "7190 0.35 0.0\n",
      "7215 0.95 0.0\n",
      "7231 0.5 0.0\n",
      "7233 0.5 0.0\n",
      "7239 0.95 0.0\n",
      "7308 0.95 0.0\n",
      "7329 0.35 0.0\n",
      "7365 0.45 0.0\n",
      "7430 0.95 0.0\n",
      "7478 1.0 0.0\n",
      "7518 0.8 0.0\n",
      "7606 0.95 0.05\n",
      "7620 1.0 0.0\n",
      "7638 0.8 0.0\n",
      "7704 0.7 0.0\n",
      "7768 1.0 0.0\n",
      "7773 0.35 0.0\n",
      "7791 0.4 0.0\n",
      "7793 0.25 0.0\n",
      "7797 1.0 0.0\n",
      "7798 0.8 0.0\n",
      "7814 0.75 0.0\n",
      "7851 0.9 0.0\n",
      "7856 0.3 0.0\n",
      "7886 0.95 0.0\n",
      "7891 0.5 0.0\n",
      "7909 0.35 0.0\n",
      "7922 0.9 0.0\n",
      "7923 0.7 0.0\n",
      "7924 0.65 0.0\n",
      "7979 0.75 0.0\n",
      "7995 0.8 0.0\n",
      "8029 0.5 0.0\n",
      "8031 0.65 0.0\n",
      "8045 0.7 0.0\n",
      "8118 0.8 0.0\n",
      "8213 0.55 0.0\n",
      "8220 0.75 0.0\n",
      "8221 0.95 0.0\n",
      "8234 0.3 0.0\n",
      "8238 0.45 0.0\n",
      "8287 0.55 0.0\n",
      "8300 1.0 0.0\n",
      "8316 0.55 0.0\n",
      "8393 0.5 0.0\n",
      "8440 0.4 0.0\n",
      "8468 0.9 0.05\n",
      "8485 0.3 0.0\n",
      "8518 0.5 0.0\n",
      "8520 0.35 0.0\n",
      "8558 0.4 0.0\n",
      "8584 0.6 0.0\n",
      "8619 0.6 0.0\n",
      "8620 0.9 0.0\n",
      "8641 0.25 0.0\n",
      "8645 0.8 0.0\n",
      "8654 0.9 0.0\n",
      "8661 0.8 0.0\n",
      "8666 0.9 0.05\n",
      "8680 1.0 0.0\n",
      "8690 1.0 0.0\n",
      "8701 0.9 0.05\n",
      "8714 1.0 0.0\n",
      "8719 0.95 0.0\n",
      "8721 0.5 0.0\n",
      "8730 0.6 0.0\n",
      "8753 0.3 0.0\n",
      "8759 0.25 0.0\n",
      "8761 0.6 0.0\n",
      "8780 0.9 0.0\n",
      "8785 0.7 0.05\n",
      "8859 0.3 0.0\n",
      "8867 0.75 0.0\n",
      "8889 0.7 0.0\n",
      "8892 0.75 0.0\n",
      "8918 0.85 0.0\n",
      "8920 0.55 0.0\n",
      "8966 0.25 0.0\n",
      "8998 0.9 0.0\n",
      "9002 0.25 0.0\n",
      "9008 0.95 0.0\n",
      "9081 0.5 0.0\n",
      "9114 0.3 0.0\n",
      "9118 0.25 0.0\n",
      "9119 0.7 0.0\n",
      "9164 0.6 0.0\n",
      "9220 0.55 0.0\n",
      "9290 0.85 0.0\n",
      "9309 0.5 0.0\n",
      "9346 0.5 0.0\n",
      "9372 0.5 0.0\n",
      "9390 1.0 0.0\n",
      "9408 0.75 0.0\n",
      "9428 0.8 0.0\n",
      "9448 0.85 0.0\n",
      "9481 0.35 0.0\n",
      "9490 0.75 0.0\n",
      "9504 0.7 0.0\n",
      "9528 1.0 0.0\n",
      "9559 0.9 0.0\n",
      "9567 0.9 0.0\n",
      "9591 0.55 0.0\n",
      "9611 0.9 0.0\n",
      "9633 0.65 0.0\n",
      "9640 0.35 0.0\n",
      "9641 0.9 0.0\n",
      "9650 0.6 0.0\n",
      "9651 0.6 0.0\n",
      "9661 0.9 0.0\n",
      "9758 0.95 0.0\n",
      "9769 0.25 0.0\n",
      "9782 0.9 0.0\n",
      "9794 0.35 0.0\n",
      "9810 0.5 0.0\n",
      "9870 0.95 0.0\n",
      "9876 0.85 0.0\n",
      "9924 0.95 0.0\n",
      "9948 0.95 0.0\n",
      "9952 0.65 0.0\n",
      "9956 0.95 0.0\n",
      "10003 0.95 0.0\n",
      "10012 0.7 0.0\n",
      "10028 0.8 0.0\n",
      "10038 0.45 0.0\n",
      "10064 0.7 0.1\n",
      "10066 0.25 0.0\n",
      "10070 0.6 0.0\n",
      "10109 0.25 0.0\n",
      "10142 0.8 0.0\n",
      "10151 0.4 0.0\n",
      "10187 0.55 0.0\n",
      "10197 0.25 0.0\n",
      "10222 0.95 0.0\n",
      "10284 0.25 0.0\n",
      "10358 0.75 0.0\n",
      "10382 0.4 0.0\n",
      "10428 0.3 0.0\n",
      "10438 0.9 0.0\n",
      "10446 0.65 0.0\n",
      "10588 0.4 0.0\n",
      "10710 0.85 0.0\n",
      "10722 0.65 0.0\n",
      "10726 0.65 0.0\n",
      "10738 0.65 0.0\n",
      "10746 0.35 0.0\n",
      "10752 0.3 0.0\n",
      "10780 1.0 0.0\n",
      "10866 0.5 0.0\n",
      "10906 0.4 0.0\n",
      "10944 0.5 0.1\n",
      "10970 0.6 0.0\n",
      "11068 0.25 0.0\n",
      "11074 1.0 0.0\n",
      "11078 0.35 0.0\n",
      "11087 0.45 0.0\n",
      "11192 1.0 0.0\n",
      "11196 0.85 0.0\n",
      "11199 0.3 0.0\n",
      "11202 0.9 0.0\n",
      "11208 0.9 0.0\n",
      "11239 0.7 0.0\n",
      "11288 0.95 0.0\n",
      "11322 0.65 0.0\n",
      "11351 0.55 0.0\n",
      "11366 0.85 0.0\n",
      "11388 0.55 0.0\n",
      "11398 0.95 0.0\n",
      "11442 0.55 0.0\n",
      "11464 0.5 0.0\n",
      "11482 0.95 0.0\n",
      "11536 0.95 0.0\n",
      "11550 0.25 0.0\n",
      "11614 0.6 0.0\n",
      "11617 0.65 0.0\n",
      "11647 0.8 0.05\n",
      "11669 0.6 0.0\n",
      "11688 0.95 0.0\n",
      "11698 0.35 0.0\n",
      "11734 0.95 0.0\n",
      "11745 0.6 0.0\n",
      "11749 0.55 0.0\n",
      "11761 0.25 0.0\n",
      "11767 0.3 0.0\n",
      "11830 0.8 0.0\n",
      "11843 0.55 0.0\n",
      "11853 0.4 0.0\n",
      "11858 0.3 0.0\n",
      "11880 0.6 0.0\n",
      "11885 0.45 0.05\n",
      "11891 0.25 0.0\n",
      "11904 0.55 0.0\n",
      "11924 0.35 0.0\n",
      "11931 0.75 0.0\n",
      "11938 0.55 0.0\n",
      "11940 0.65 0.0\n",
      "11950 0.65 0.0\n",
      "11984 0.25 0.0\n",
      "11992 1.0 0.0\n",
      "12066 0.85 0.0\n",
      "12076 1.0 0.0\n",
      "12112 0.65 0.0\n",
      "12127 0.35 0.0\n",
      "12190 0.95 0.0\n",
      "12257 0.65 0.0\n",
      "12268 0.8 0.05\n",
      "12272 0.85 0.0\n",
      "12282 0.25 0.0\n",
      "12288 0.35 0.0\n",
      "12297 0.75 0.0\n",
      "12305 0.85 0.0\n",
      "12320 0.25 0.0\n",
      "12368 0.85 0.0\n",
      "12406 0.6 0.0\n",
      "12440 0.7 0.0\n",
      "12466 0.25 0.0\n",
      "12493 0.9 0.0\n",
      "12494 1.0 0.0\n",
      "12513 0.85 0.0\n",
      "12562 0.75 0.0\n",
      "12586 0.25 0.0\n",
      "12594 0.9 0.0\n",
      "12614 0.9 0.0\n",
      "12623 0.95 0.0\n",
      "12630 0.9 0.0\n",
      "12646 0.85 0.0\n",
      "12651 1.0 0.0\n",
      "12655 0.4 0.0\n",
      "12663 0.95 0.0\n",
      "12739 0.35 0.0\n",
      "12767 0.3 0.0\n",
      "12768 0.25 0.0\n",
      "12778 0.95 0.0\n",
      "12792 0.75 0.0\n",
      "12840 0.7 0.0\n",
      "12868 0.65 0.0\n",
      "12884 1.0 0.0\n",
      "12900 1.0 0.0\n",
      "12914 0.4 0.0\n",
      "12934 0.65 0.0\n",
      "12936 0.75 0.15\n",
      "12946 0.75 0.0\n",
      "12984 0.75 0.0\n",
      "12989 0.4 0.0\n",
      "12999 0.7 0.0\n",
      "13002 0.75 0.0\n",
      "13012 0.65 0.0\n",
      "13014 0.65 0.0\n",
      "13018 1.0 0.0\n",
      "13049 0.35 0.0\n",
      "13050 0.65 0.0\n",
      "13096 0.55 0.0\n",
      "13103 0.45 0.0\n",
      "13153 0.55 0.0\n",
      "13191 0.85 0.0\n",
      "13194 0.4 0.0\n",
      "13308 1.0 0.0\n",
      "13346 0.35 0.0\n",
      "13407 0.25 0.0\n",
      "13428 0.95 0.0\n",
      "13440 0.7 0.0\n",
      "13526 0.7 0.0\n",
      "13554 0.7 0.0\n",
      "13588 0.45 0.0\n",
      "13655 0.95 0.0\n",
      "13666 0.75 0.0\n",
      "13677 0.95 0.0\n",
      "13678 0.4 0.0\n",
      "13680 1.0 0.0\n",
      "13698 0.7 0.0\n",
      "13742 0.85 0.0\n",
      "13752 1.0 0.0\n",
      "13781 0.5 0.0\n",
      "13797 0.35 0.0\n",
      "13812 0.4 0.0\n",
      "13866 0.85 0.0\n",
      "13876 0.95 0.0\n",
      "13897 0.5 0.0\n",
      "13904 0.75 0.0\n",
      "13920 1.0 0.0\n",
      "13982 0.8 0.0\n",
      "13996 1.0 0.0\n",
      "13998 0.9 0.0\n",
      "14008 0.5 0.1\n",
      "14020 0.45 0.0\n",
      "14042 1.0 0.0\n",
      "14062 0.85 0.0\n",
      "14120 1.0 0.0\n",
      "14128 0.75 0.0\n",
      "14162 0.55 0.0\n",
      "14208 0.4 0.0\n",
      "14222 1.0 0.1\n",
      "14249 0.6 0.0\n",
      "14254 0.8 0.0\n",
      "14281 0.95 0.0\n",
      "14294 0.25 0.0\n",
      "14305 0.9 0.0\n",
      "14341 0.65 0.0\n",
      "14385 0.9 0.1\n",
      "14406 0.65 0.0\n",
      "14413 0.7 0.0\n",
      "14480 0.95 0.1\n",
      "14504 0.75 0.0\n",
      "14579 0.45 0.0\n",
      "14580 0.95 0.0\n",
      "14607 0.95 0.0\n",
      "14611 0.45 0.0\n",
      "14627 0.3 0.0\n",
      "14645 0.45 0.0\n",
      "14664 0.95 0.0\n",
      "14665 0.7 0.0\n",
      "14690 0.8 0.0\n",
      "14697 0.7 0.0\n",
      "14706 0.75 0.0\n",
      "14716 0.3 0.0\n",
      "14726 0.75 0.0\n",
      "14728 0.4 0.0\n",
      "14733 0.35 0.0\n",
      "14751 0.5 0.0\n",
      "14754 0.4 0.0\n",
      "14762 0.95 0.0\n",
      "14790 1.0 0.0\n",
      "14796 1.0 0.0\n",
      "14815 0.35 0.0\n",
      "14830 0.45 0.0\n",
      "14844 0.35 0.0\n",
      "14872 0.25 0.0\n",
      "14886 0.85 0.0\n",
      "14896 0.85 0.0\n",
      "14950 0.6 0.0\n",
      "14968 0.95 0.0\n",
      "14984 0.25 0.0\n",
      "15072 0.25 0.0\n",
      "15167 0.5 0.0\n",
      "15170 0.45 0.0\n",
      "15239 0.65 0.0\n",
      "15244 0.8 0.0\n",
      "15247 0.3 0.0\n",
      "15309 0.8 0.0\n",
      "15354 0.95 0.0\n",
      "15360 0.3 0.0\n",
      "15366 0.7 0.0\n",
      "15381 0.9 0.0\n",
      "15424 0.65 0.0\n",
      "15515 0.3 0.0\n",
      "15522 0.4 0.0\n",
      "15532 0.75 0.0\n",
      "15562 0.25 0.0\n",
      "15584 0.75 0.0\n",
      "15610 0.95 0.0\n",
      "15616 0.55 0.05\n",
      "15623 0.4 0.0\n",
      "15629 0.8 0.0\n",
      "15666 0.8 0.0\n",
      "15724 0.8 0.0\n",
      "15725 0.7 0.0\n",
      "15728 0.95 0.0\n",
      "15738 0.3 0.0\n",
      "15739 0.3 0.0\n",
      "15745 0.3 0.0\n",
      "15755 0.85 0.0\n",
      "15775 0.3 0.0\n",
      "15820 0.6 0.0\n",
      "15827 0.8 0.0\n",
      "15832 0.9 0.0\n",
      "15860 0.5 0.0\n",
      "15879 0.65 0.0\n",
      "15894 1.0 0.0\n",
      "15912 0.3 0.0\n",
      "15913 0.9 0.0\n",
      "15956 0.65 0.0\n",
      "15987 0.95 0.0\n",
      "15988 0.9 0.0\n",
      "15991 0.85 0.05\n",
      "16022 0.85 0.0\n",
      "16023 0.7 0.0\n",
      "16026 0.3 0.0\n",
      "16036 0.95 0.0\n",
      "16044 0.9 0.0\n",
      "16066 0.25 0.0\n",
      "16170 0.75 0.0\n",
      "16173 1.0 0.0\n",
      "16201 0.35 0.0\n",
      "16266 0.85 0.0\n",
      "16270 0.35 0.0\n",
      "16277 0.25 0.0\n",
      "16282 0.55 0.05\n",
      "16398 0.8 0.0\n",
      "16444 0.75 0.0\n",
      "16467 0.25 0.0\n",
      "16486 0.25 0.0\n",
      "16488 1.0 0.0\n",
      "16570 0.5 0.0\n",
      "16581 0.8 0.0\n",
      "16622 0.45 0.0\n",
      "16628 0.6 0.0\n",
      "16635 0.6 0.0\n",
      "16658 1.0 0.0\n",
      "16688 1.0 0.0\n",
      "16799 0.35 0.0\n",
      "16804 0.7 0.0\n",
      "16816 0.45 0.0\n",
      "16860 0.6 0.0\n",
      "16918 1.0 0.05\n",
      "16937 0.85 0.0\n",
      "16939 0.65 0.0\n",
      "16951 0.25 0.0\n",
      "16953 0.9 0.0\n",
      "16964 0.95 0.0\n",
      "16992 0.35 0.0\n",
      "17019 0.9 0.0\n",
      "17027 0.35 0.0\n",
      "17055 0.85 0.0\n",
      "17060 0.3 0.0\n",
      "17061 0.4 0.0\n",
      "17111 0.35 0.0\n",
      "17112 0.85 0.0\n",
      "17121 0.55 0.0\n",
      "17128 0.45 0.0\n",
      "17178 0.9 0.0\n",
      "17186 0.55 0.0\n",
      "17190 0.95 0.0\n",
      "17222 0.4 0.0\n",
      "17244 0.95 0.0\n",
      "17291 0.45 0.0\n",
      "17296 0.8 0.0\n",
      "17362 0.55 0.0\n",
      "17364 0.25 0.0\n",
      "17384 0.35 0.0\n",
      "17456 0.7 0.0\n",
      "17529 0.75 0.0\n",
      "17551 0.85 0.05\n",
      "17591 0.9 0.0\n",
      "17594 0.85 0.05\n",
      "17602 0.25 0.0\n",
      "17641 0.6 0.0\n",
      "17666 0.6 0.0\n",
      "17679 0.25 0.0\n",
      "17682 0.8 0.0\n",
      "17689 0.4 0.0\n",
      "17698 0.75 0.0\n",
      "17700 0.8 0.0\n",
      "17737 0.4 0.0\n",
      "17756 0.4 0.0\n",
      "17784 0.7 0.0\n",
      "17792 0.9 0.0\n",
      "17808 0.7 0.0\n",
      "17817 0.7 0.05\n",
      "17824 0.65 0.0\n",
      "17827 0.8 0.0\n",
      "17889 0.6 0.0\n",
      "17894 0.3 0.0\n",
      "17899 0.8 0.0\n",
      "17924 0.75 0.0\n",
      "17958 1.0 0.0\n",
      "18118 1.0 0.0\n",
      "18126 0.35 0.0\n",
      "18130 0.9 0.0\n",
      "18146 0.25 0.0\n",
      "18166 0.95 0.0\n",
      "18187 0.65 0.0\n",
      "18228 0.9 0.0\n",
      "18288 0.75 0.0\n",
      "18348 0.7 0.1\n",
      "18378 0.5 0.0\n",
      "18382 1.0 0.0\n",
      "18405 0.7 0.0\n",
      "18506 0.95 0.0\n",
      "18510 0.85 0.0\n",
      "18562 0.35 0.0\n",
      "18574 0.3 0.0\n",
      "18580 0.65 0.0\n",
      "18598 0.9 0.0\n",
      "18610 0.45 0.0\n",
      "18669 0.25 0.0\n",
      "18688 0.7 0.0\n",
      "18690 0.3 0.0\n",
      "18728 0.6 0.0\n",
      "18740 0.85 0.0\n",
      "18928 0.6 0.0\n",
      "18976 0.65 0.0\n",
      "18984 0.55 0.0\n",
      "19005 0.95 0.05\n",
      "19025 0.85 0.0\n",
      "19067 0.7 0.0\n",
      "19098 0.35 0.0\n",
      "19120 0.3 0.0\n",
      "19124 0.25 0.0\n",
      "19137 0.55 0.0\n",
      "19148 0.75 0.0\n",
      "19159 0.9 0.0\n",
      "19163 0.45 0.0\n",
      "19190 0.5 0.0\n",
      "19194 0.35 0.0\n",
      "19212 1.0 0.0\n",
      "19220 0.75 0.0\n",
      "19244 0.6 0.1\n",
      "19254 0.8 0.0\n",
      "19255 0.35 0.0\n",
      "19300 0.45 0.0\n",
      "19310 0.4 0.0\n",
      "19322 0.3 0.0\n",
      "19350 0.6 0.0\n",
      "19362 0.75 0.0\n",
      "19365 0.95 0.0\n",
      "19412 1.0 0.05\n",
      "19417 0.25 0.0\n",
      "19428 0.95 0.0\n",
      "19494 0.95 0.05\n",
      "19546 0.3 0.0\n",
      "19566 0.55 0.0\n",
      "19576 0.95 0.0\n",
      "19586 0.6 0.0\n",
      "19597 0.45 0.0\n",
      "19616 0.55 0.0\n",
      "19667 0.35 0.0\n",
      "19692 0.9 0.0\n",
      "19716 0.4 0.0\n",
      "19778 0.25 0.0\n",
      "19814 1.0 0.0\n",
      "19824 0.85 0.0\n",
      "19860 0.8 0.0\n",
      "19906 0.25 0.0\n",
      "19914 0.85 0.0\n",
      "19928 0.45 0.0\n",
      "19934 0.95 0.0\n",
      "19948 0.5 0.0\n",
      "19951 0.35 0.0\n",
      "19972 0.35 0.0\n",
      "19981 0.4 0.0\n",
      "19988 0.9 0.0\n",
      "20015 0.35 0.0\n",
      "20025 0.25 0.0\n",
      "20035 0.45 0.0\n",
      "20037 0.9 0.0\n",
      "20050 1.0 0.0\n",
      "20054 0.65 0.0\n",
      "20068 1.0 0.0\n",
      "20116 0.95 0.05\n",
      "20138 0.3 0.0\n",
      "20170 0.95 0.0\n",
      "20184 0.25 0.0\n",
      "20188 0.5 0.0\n",
      "20196 0.3 0.0\n",
      "20204 0.95 0.0\n",
      "20248 1.0 0.0\n",
      "20264 0.6 0.0\n",
      "20308 0.35 0.0\n",
      "20328 0.8 0.0\n",
      "20350 0.45 0.05\n",
      "20363 0.85 0.0\n",
      "20366 0.25 0.0\n",
      "20402 0.6 0.0\n",
      "20412 0.75 0.0\n",
      "20508 0.35 0.0\n",
      "20518 0.7 0.0\n",
      "20560 0.35 0.0\n",
      "20578 0.85 0.0\n",
      "20614 0.95 0.0\n",
      "20630 0.35 0.0\n",
      "20636 0.9 0.0\n",
      "20641 0.95 0.15\n",
      "20660 0.9 0.0\n",
      "20676 0.25 0.0\n",
      "20684 0.35 0.0\n",
      "20709 0.9 0.1\n",
      "20734 0.35 0.0\n",
      "20735 0.95 0.2\n",
      "20750 0.65 0.0\n",
      "20758 0.5 0.0\n",
      "20767 0.7 0.0\n",
      "20792 0.9 0.0\n",
      "20811 0.75 0.0\n",
      "20820 0.95 0.0\n",
      "20825 0.55 0.0\n",
      "20830 0.7 0.0\n",
      "20859 0.85 0.05\n",
      "20893 0.7 0.0\n",
      "20905 0.75 0.0\n",
      "20918 0.9 0.0\n",
      "20919 0.4 0.0\n",
      "20920 0.9 0.0\n",
      "20945 0.3 0.0\n",
      "20954 0.4 0.0\n",
      "20964 0.8 0.0\n",
      "20966 1.0 0.0\n",
      "20975 0.55 0.0\n",
      "21040 0.35 0.0\n",
      "21046 1.0 0.0\n",
      "21110 0.5 0.0\n",
      "21158 0.55 0.0\n",
      "21189 0.25 0.0\n",
      "21295 0.3 0.0\n",
      "21297 0.65 0.0\n",
      "21302 1.0 0.0\n",
      "21317 0.3 0.0\n",
      "21351 0.9 0.05\n",
      "21361 0.9 0.0\n",
      "21369 0.75 0.0\n",
      "21389 0.3 0.0\n",
      "21421 0.85 0.0\n",
      "21423 0.25 0.0\n",
      "21445 0.95 0.05\n",
      "21467 0.5 0.0\n",
      "21471 0.5 0.0\n",
      "21495 0.85 0.0\n",
      "21509 0.95 0.0\n",
      "21529 0.35 0.0\n",
      "21540 0.55 0.0\n",
      "21589 0.6 0.0\n",
      "21650 0.3 0.0\n",
      "21686 0.8 0.0\n",
      "21688 0.9 0.05\n",
      "21705 0.35 0.0\n",
      "21826 0.65 0.0\n",
      "21842 0.95 0.0\n",
      "21896 0.95 0.0\n",
      "22072 0.85 0.0\n",
      "22078 0.4 0.0\n",
      "22081 0.6 0.0\n",
      "22123 0.9 0.0\n",
      "22136 0.6 0.0\n",
      "22140 0.95 0.0\n",
      "22263 0.25 0.0\n",
      "22274 0.3 0.0\n",
      "22283 0.85 0.0\n",
      "22308 0.9 0.0\n",
      "22320 0.95 0.0\n",
      "22438 0.8 0.0\n",
      "22447 0.4 0.0\n",
      "22483 0.25 0.0\n",
      "22484 0.4 0.0\n",
      "22503 0.85 0.0\n",
      "22505 0.95 0.0\n",
      "22514 0.65 0.0\n",
      "22521 0.95 0.0\n",
      "22523 1.0 0.0\n",
      "22532 0.25 0.0\n",
      "22543 0.9 0.0\n",
      "22549 0.35 0.0\n",
      "22591 0.35 0.0\n",
      "22597 0.7 0.0\n",
      "22648 0.75 0.0\n",
      "22664 0.7 0.0\n",
      "22692 0.8 0.0\n",
      "22719 0.9 0.0\n",
      "22755 0.35 0.0\n",
      "22804 1.0 0.0\n",
      "22824 0.8 0.0\n",
      "22924 0.7 0.0\n",
      "22934 0.35 0.0\n",
      "22976 0.75 0.0\n",
      "23008 0.75 0.0\n",
      "23016 1.0 0.05\n",
      "23078 0.35 0.0\n",
      "23086 0.9 0.05\n",
      "23100 0.85 0.0\n",
      "23184 0.85 0.0\n",
      "23212 0.9 0.0\n",
      "23215 0.4 0.0\n",
      "23243 0.25 0.0\n",
      "23350 0.7 0.0\n",
      "23366 1.0 0.0\n",
      "23400 0.9 0.0\n",
      "23422 0.75 0.0\n",
      "23458 0.8 0.0\n",
      "23463 0.35 0.0\n",
      "23582 0.75 0.0\n",
      "23674 0.8 0.0\n",
      "23680 0.25 0.0\n",
      "23682 0.55 0.0\n",
      "23710 0.9 0.0\n",
      "23732 0.45 0.0\n",
      "23743 0.3 0.0\n",
      "23791 0.7 0.0\n",
      "23865 0.35 0.0\n",
      "23868 0.7 0.0\n",
      "23948 0.5 0.0\n",
      "23964 0.6 0.0\n",
      "24006 0.65 0.0\n",
      "24046 0.5 0.0\n",
      "24062 0.75 0.0\n",
      "24101 0.9 0.0\n",
      "24108 0.55 0.0\n",
      "24134 0.85 0.0\n",
      "24150 0.25 0.0\n",
      "24164 0.95 0.0\n",
      "24210 0.85 0.0\n",
      "24240 0.8 0.0\n",
      "24256 0.5 0.0\n",
      "24261 0.25 0.0\n",
      "24263 0.85 0.0\n",
      "24337 0.3 0.0\n",
      "24404 0.3 0.0\n",
      "24457 0.65 0.0\n",
      "24479 0.85 0.0\n",
      "24494 0.85 0.0\n",
      "24497 0.8 0.0\n",
      "24533 0.85 0.0\n",
      "24558 0.55 0.0\n",
      "24562 0.85 0.0\n",
      "24587 1.0 0.0\n",
      "24589 0.95 0.0\n",
      "24598 1.0 0.0\n",
      "24613 1.0 0.0\n",
      "24620 0.5 0.0\n",
      "24646 0.65 0.0\n",
      "24684 0.95 0.0\n",
      "24720 0.9 0.0\n",
      "24740 0.85 0.0\n",
      "24756 0.8 0.0\n",
      "24760 0.65 0.0\n",
      "24821 0.5 0.0\n",
      "24831 0.35 0.0\n",
      "24860 1.0 0.0\n",
      "24898 0.85 0.0\n",
      "24916 0.25 0.0\n",
      "24927 0.95 0.0\n",
      "24953 0.3 0.0\n",
      "24979 0.5 0.0\n",
      "24983 0.35 0.0\n",
      "24991 0.4 0.0\n",
      "24998 0.75 0.0\n",
      "25015 0.85 0.0\n",
      "25212 0.8 0.0\n",
      "25224 0.6 0.0\n",
      "25232 0.9 0.0\n",
      "25256 0.45 0.0\n",
      "25262 1.0 0.0\n",
      "25298 0.95 0.0\n",
      "25301 0.25 0.0\n",
      "25321 0.8 0.0\n",
      "25478 0.35 0.0\n",
      "25482 0.95 0.0\n",
      "25486 1.0 0.0\n",
      "25495 0.35 0.0\n",
      "25528 0.8 0.0\n",
      "25546 0.6 0.05\n",
      "25624 0.5 0.0\n",
      "25634 0.95 0.0\n",
      "25648 0.7 0.0\n",
      "25652 0.85 0.0\n",
      "25657 0.5 0.05\n",
      "25661 0.4 0.0\n",
      "25664 0.7 0.0\n",
      "25692 0.35 0.0\n",
      "25698 0.8 0.0\n",
      "25706 0.3 0.0\n",
      "25799 1.0 0.0\n",
      "25801 0.9 0.0\n",
      "25819 0.7 0.0\n",
      "25874 0.95 0.0\n",
      "25879 0.45 0.0\n",
      "25905 0.35 0.0\n",
      "25909 0.95 0.0\n",
      "25946 0.65 0.0\n",
      "25947 0.5 0.0\n",
      "25951 0.25 0.0\n",
      "25965 0.9 0.0\n",
      "25968 0.7 0.0\n",
      "25976 0.4 0.0\n",
      "25986 0.75 0.0\n",
      "26023 0.85 0.0\n",
      "26061 0.55 0.0\n",
      "26079 0.85 0.0\n",
      "26135 1.0 0.05\n",
      "26203 0.45 0.0\n",
      "26214 0.9 0.0\n",
      "26223 0.45 0.0\n",
      "26231 0.9 0.0\n",
      "26275 0.25 0.0\n",
      "26294 0.8 0.0\n",
      "26302 0.55 0.0\n",
      "26332 0.25 0.0\n",
      "26362 0.8 0.0\n",
      "26380 0.45 0.0\n",
      "26405 1.0 0.0\n",
      "26426 0.25 0.0\n",
      "26428 0.4 0.0\n",
      "26513 0.25 0.0\n",
      "26527 0.95 0.0\n",
      "26616 0.25 0.0\n",
      "26640 0.95 0.05\n",
      "26663 0.3 0.0\n",
      "26681 0.7 0.0\n",
      "26703 0.7 0.0\n",
      "26708 1.0 0.0\n",
      "26730 0.9 0.0\n",
      "26760 0.9 0.0\n",
      "26762 0.95 0.0\n",
      "26822 0.35 0.0\n",
      "26852 0.85 0.1\n",
      "26860 0.35 0.0\n",
      "26865 0.75 0.0\n",
      "26877 0.35 0.0\n",
      "26950 0.85 0.0\n",
      "27016 0.95 0.0\n",
      "27029 0.8 0.0\n",
      "27045 0.85 0.0\n",
      "27051 0.4 0.0\n",
      "27072 0.35 0.0\n",
      "27074 0.7 0.0\n",
      "27085 0.9 0.1\n",
      "27107 0.5 0.0\n",
      "27118 0.9 0.0\n",
      "27121 0.45 0.0\n",
      "27185 0.3 0.0\n",
      "27197 0.35 0.0\n",
      "27241 0.9 0.0\n",
      "27293 0.3 0.0\n",
      "27299 0.95 0.0\n",
      "27312 1.0 0.0\n",
      "27323 0.5 0.0\n",
      "27324 0.55 0.0\n",
      "27344 0.3 0.0\n",
      "27348 0.55 0.0\n",
      "27358 0.85 0.05\n",
      "27370 0.8 0.0\n",
      "27418 0.4 0.0\n",
      "27447 0.25 0.0\n",
      "27459 0.45 0.0\n",
      "27545 0.9 0.0\n",
      "27596 0.75 0.0\n",
      "27601 0.8 0.0\n",
      "27661 1.0 0.0\n",
      "27678 0.4 0.0\n",
      "27725 0.6 0.0\n",
      "27729 0.95 0.0\n",
      "27730 0.25 0.0\n",
      "27732 1.0 0.1\n",
      "27740 0.85 0.0\n",
      "27780 0.95 0.0\n",
      "27846 0.5 0.1\n",
      "27902 0.4 0.0\n",
      "27908 0.65 0.0\n",
      "27910 0.55 0.0\n",
      "27964 0.85 0.0\n",
      "27966 0.85 0.0\n",
      "27968 0.95 0.0\n",
      "28088 0.9 0.0\n",
      "28136 1.0 0.0\n",
      "28149 0.9 0.0\n",
      "28182 0.4 0.0\n",
      "28183 0.75 0.0\n",
      "28192 1.0 0.0\n",
      "28195 0.85 0.0\n",
      "28213 0.75 0.0\n",
      "28215 0.85 0.0\n",
      "28226 0.4 0.0\n",
      "28260 0.9 0.05\n",
      "28262 0.75 0.0\n",
      "28279 1.0 0.05\n",
      "28306 0.5 0.0\n",
      "28368 0.85 0.0\n",
      "28396 0.8 0.0\n",
      "28422 0.85 0.1\n",
      "28448 0.3 0.0\n",
      "28463 0.4 0.0\n",
      "28506 0.85 0.0\n",
      "28530 1.0 0.0\n",
      "28539 0.55 0.0\n",
      "28564 0.3 0.0\n",
      "28574 0.95 0.0\n",
      "28592 1.0 0.0\n",
      "28648 0.25 0.0\n",
      "28664 0.7 0.0\n",
      "28674 0.35 0.0\n",
      "28676 0.4 0.0\n",
      "28710 0.45 0.05\n",
      "28719 0.75 0.0\n",
      "28788 0.85 0.1\n",
      "28908 0.25 0.0\n",
      "28928 0.5 0.0\n",
      "28984 0.9 0.0\n",
      "29012 0.75 0.0\n",
      "29026 0.35 0.0\n",
      "29093 0.5 0.0\n",
      "29124 0.25 0.0\n",
      "29132 0.25 0.0\n",
      "29134 0.55 0.0\n",
      "29142 0.65 0.0\n",
      "29172 0.7 0.05\n",
      "29179 0.8 0.0\n",
      "29180 1.0 0.0\n",
      "29259 0.65 0.0\n",
      "29286 0.55 0.0\n",
      "29292 0.95 0.0\n",
      "29303 0.35 0.0\n",
      "29306 0.35 0.0\n",
      "29335 0.85 0.0\n",
      "29360 0.35 0.0\n",
      "29365 0.95 0.15\n",
      "29390 0.55 0.0\n",
      "29472 0.25 0.0\n",
      "29589 0.45 0.0\n",
      "29660 0.5 0.0\n",
      "29672 0.6 0.05\n",
      "29700 0.4 0.0\n",
      "29711 0.75 0.0\n",
      "29751 0.95 0.05\n",
      "29831 0.6 0.0\n",
      "29841 0.45 0.0\n",
      "29856 0.65 0.0\n",
      "29868 0.4 0.0\n",
      "29886 0.85 0.0\n",
      "29933 0.5 0.0\n",
      "29938 0.85 0.15\n",
      "29945 0.5 0.0\n",
      "29959 0.95 0.0\n",
      "29973 0.55 0.0\n",
      "29993 0.85 0.0\n",
      "29996 0.85 0.0\n",
      "30085 0.6 0.0\n",
      "30111 0.5 0.0\n",
      "30116 0.25 0.0\n",
      "30144 0.75 0.0\n",
      "30147 0.65 0.0\n",
      "30181 0.3 0.0\n",
      "30184 0.9 0.0\n",
      "30308 0.95 0.0\n",
      "30322 0.3 0.0\n",
      "30334 0.3 0.0\n",
      "30383 0.6 0.0\n",
      "30416 0.8 0.0\n",
      "30418 0.45 0.0\n",
      "30446 0.3 0.0\n",
      "30452 0.95 0.05\n",
      "30453 0.75 0.0\n",
      "30478 0.4 0.0\n",
      "30517 0.3 0.0\n",
      "30521 0.5 0.0\n",
      "30523 0.3 0.0\n",
      "30525 0.85 0.0\n",
      "30545 0.6 0.0\n",
      "30546 0.8 0.0\n",
      "30551 1.0 0.0\n",
      "30584 0.25 0.0\n",
      "30598 0.65 0.0\n",
      "30646 0.75 0.0\n",
      "30660 1.0 0.0\n",
      "30686 0.3 0.0\n",
      "30688 0.4 0.0\n",
      "30698 0.4 0.0\n",
      "30735 0.3 0.0\n",
      "30750 0.25 0.0\n",
      "30758 0.4 0.0\n",
      "30776 0.85 0.0\n",
      "30834 0.85 0.0\n",
      "30838 1.0 0.0\n",
      "30844 0.8 0.0\n",
      "30870 1.0 0.0\n",
      "31030 0.45 0.0\n",
      "31074 0.35 0.0\n",
      "31089 0.25 0.0\n",
      "31094 0.7 0.0\n",
      "31103 0.7 0.0\n",
      "31124 0.6 0.0\n",
      "31142 0.3 0.0\n",
      "31184 0.5 0.0\n",
      "31200 0.45 0.0\n",
      "31273 0.95 0.0\n",
      "31275 1.0 0.05\n",
      "31293 0.85 0.0\n",
      "31295 1.0 0.0\n",
      "31308 0.55 0.0\n",
      "31312 0.55 0.0\n",
      "31336 0.75 0.0\n",
      "31351 1.0 0.0\n",
      "31444 0.45 0.0\n",
      "31468 0.4 0.0\n",
      "31474 0.6 0.0\n",
      "31530 1.0 0.0\n",
      "31591 0.55 0.0\n",
      "31593 0.3 0.0\n",
      "31600 0.7 0.0\n",
      "31622 0.35 0.0\n",
      "31652 1.0 0.0\n",
      "31656 0.25 0.0\n",
      "31659 0.25 0.0\n",
      "31675 1.0 0.0\n",
      "31706 0.85 0.0\n",
      "31710 0.95 0.05\n",
      "31733 0.3 0.0\n",
      "31738 0.95 0.0\n",
      "31760 0.95 0.0\n",
      "31786 0.5 0.0\n",
      "31798 0.5 0.0\n",
      "31840 1.0 0.0\n",
      "31845 0.25 0.0\n",
      "31851 0.3 0.0\n",
      "31854 1.0 0.05\n",
      "31866 0.95 0.0\n",
      "31876 0.7 0.0\n",
      "31917 0.3 0.0\n",
      "31919 0.3 0.0\n",
      "31934 0.95 0.0\n",
      "31938 0.35 0.0\n",
      "31942 0.55 0.0\n",
      "32016 1.0 0.0\n",
      "32018 0.9 0.05\n",
      "32047 0.95 0.0\n",
      "32066 0.85 0.0\n",
      "32068 0.5 0.0\n",
      "32072 0.9 0.0\n",
      "32100 0.6 0.0\n",
      "32152 0.8 0.0\n",
      "32199 0.6 0.0\n",
      "32206 0.25 0.0\n",
      "32235 0.35 0.0\n",
      "32244 1.0 0.0\n",
      "32251 0.4 0.0\n",
      "32256 0.4 0.0\n",
      "32349 0.25 0.0\n",
      "32351 0.35 0.0\n",
      "32355 0.25 0.0\n",
      "32396 0.85 0.0\n",
      "32410 0.4 0.0\n",
      "32417 1.0 0.0\n",
      "32426 0.35 0.0\n",
      "32452 0.35 0.0\n",
      "32453 0.6 0.0\n",
      "32456 0.8 0.0\n",
      "32457 0.85 0.0\n",
      "32473 0.3 0.0\n",
      "32573 0.8 0.05\n",
      "32596 0.4 0.0\n",
      "32618 0.25 0.0\n",
      "32668 1.0 0.0\n",
      "32672 0.4 0.0\n",
      "32712 0.4 0.0\n",
      "32735 0.45 0.0\n",
      "32747 0.55 0.15\n",
      "32760 0.5 0.0\n",
      "32766 0.55 0.0\n",
      "32774 0.9 0.0\n",
      "32784 0.8 0.0\n",
      "32878 0.65 0.1\n",
      "32898 0.55 0.0\n",
      "32908 0.6 0.0\n",
      "32916 0.25 0.0\n",
      "32926 0.7 0.0\n",
      "32930 0.55 0.0\n",
      "32963 0.5 0.0\n",
      "32968 0.45 0.0\n",
      "33059 0.7 0.0\n",
      "33074 0.35 0.0\n",
      "33130 0.95 0.05\n",
      "33150 0.95 0.05\n",
      "33162 0.85 0.0\n",
      "33182 0.6 0.0\n",
      "33198 0.75 0.0\n",
      "33226 0.7 0.0\n",
      "33246 0.45 0.0\n",
      "33338 0.95 0.0\n",
      "33358 0.25 0.0\n",
      "33388 0.85 0.0\n",
      "33422 1.0 0.0\n",
      "33443 0.25 0.0\n",
      "33519 0.3 0.0\n",
      "33576 0.85 0.0\n",
      "33581 0.95 0.0\n",
      "33611 0.55 0.0\n",
      "33664 0.85 0.0\n",
      "33768 0.8 0.05\n",
      "33780 0.45 0.0\n",
      "33806 0.55 0.0\n",
      "33860 0.9 0.0\n",
      "33862 0.25 0.0\n",
      "33974 0.85 0.0\n",
      "33976 0.3 0.0\n",
      "33997 0.25 0.0\n",
      "34034 0.45 0.0\n",
      "34040 0.3 0.0\n",
      "34090 0.35 0.05\n",
      "34147 0.6 0.0\n",
      "34300 0.25 0.0\n",
      "34304 0.5 0.0\n",
      "34306 0.8 0.0\n",
      "34328 0.6 0.0\n",
      "34330 0.3 0.0\n",
      "34377 0.75 0.0\n",
      "34414 0.7 0.0\n",
      "34422 0.85 0.0\n",
      "34437 0.25 0.0\n",
      "34496 0.75 0.0\n",
      "34500 0.9 0.0\n",
      "34524 0.8 0.0\n",
      "34540 0.5 0.0\n",
      "34574 0.8 0.0\n",
      "34592 0.75 0.0\n",
      "34594 0.75 0.0\n",
      "34615 0.95 0.05\n",
      "34665 0.95 0.0\n",
      "34668 0.3 0.0\n",
      "34678 0.95 0.0\n",
      "34688 0.6 0.0\n",
      "34707 0.95 0.0\n",
      "34739 0.6 0.0\n",
      "34758 0.85 0.0\n",
      "34761 0.45 0.0\n",
      "34785 0.9 0.05\n",
      "34819 0.4 0.0\n",
      "34824 0.3 0.0\n",
      "34872 0.85 0.0\n",
      "34876 0.25 0.0\n",
      "34878 0.45 0.0\n",
      "34883 0.55 0.0\n",
      "34920 1.0 0.0\n",
      "34930 0.7 0.0\n",
      "34942 0.85 0.05\n",
      "34946 0.3 0.0\n",
      "34968 0.95 0.0\n",
      "35004 0.25 0.0\n",
      "35068 0.95 0.0\n",
      "35088 0.25 0.0\n",
      "35160 0.55 0.0\n",
      "35246 0.7 0.0\n",
      "35332 0.7 0.0\n",
      "35421 0.9 0.0\n",
      "35464 0.75 0.0\n",
      "35503 0.35 0.0\n",
      "35543 0.6 0.0\n",
      "35641 0.3 0.0\n",
      "35694 0.95 0.0\n",
      "35804 0.65 0.0\n",
      "35836 0.35 0.0\n",
      "35843 0.7 0.0\n",
      "35916 0.6 0.0\n",
      "35991 1.0 0.0\n",
      "35996 0.55 0.0\n",
      "35997 0.8 0.0\n",
      "36000 0.4 0.0\n",
      "36008 0.45 0.0\n",
      "36013 0.5 0.0\n",
      "36024 0.8 0.0\n",
      "36029 0.25 0.0\n",
      "36035 0.25 0.0\n",
      "36080 0.55 0.0\n",
      "36099 0.85 0.0\n",
      "36109 0.9 0.0\n",
      "36161 0.35 0.0\n",
      "36172 0.95 0.0\n",
      "36196 0.4 0.0\n",
      "36224 0.8 0.0\n",
      "36270 0.35 0.0\n",
      "36282 0.85 0.0\n",
      "36320 0.5 0.0\n",
      "36348 0.95 0.0\n",
      "36370 0.8 0.0\n",
      "36392 0.6 0.0\n",
      "36402 0.4 0.0\n",
      "36473 0.5 0.0\n",
      "36474 0.55 0.0\n",
      "36486 0.7 0.0\n",
      "36489 0.3 0.0\n",
      "36526 0.65 0.0\n",
      "36550 0.95 0.0\n",
      "36576 0.35 0.0\n",
      "36598 0.95 0.0\n",
      "36606 0.95 0.0\n",
      "36648 0.35 0.0\n",
      "36670 0.5 0.0\n",
      "36757 0.45 0.0\n",
      "36770 0.3 0.0\n",
      "36782 0.4 0.0\n",
      "36808 0.5 0.0\n",
      "36816 0.45 0.0\n",
      "36820 0.45 0.0\n",
      "36828 0.45 0.0\n",
      "36861 0.3 0.0\n",
      "36878 0.95 0.0\n",
      "36886 0.5 0.0\n",
      "36920 0.65 0.0\n",
      "37026 1.0 0.0\n",
      "37048 0.85 0.0\n",
      "37060 0.95 0.0\n",
      "37062 0.75 0.15\n",
      "37075 0.3 0.0\n",
      "37078 0.85 0.0\n",
      "37136 0.4 0.0\n",
      "37185 0.5 0.0\n",
      "37198 0.95 0.1\n",
      "37247 0.7 0.0\n",
      "37281 1.0 0.0\n",
      "37316 0.8 0.0\n",
      "37318 0.4 0.0\n",
      "37344 0.55 0.0\n",
      "37352 0.9 0.0\n",
      "37396 0.85 0.05\n",
      "37400 0.55 0.0\n",
      "37406 0.65 0.05\n",
      "37417 0.8 0.05\n",
      "37460 0.55 0.0\n",
      "37522 0.95 0.0\n",
      "37538 1.0 0.0\n",
      "37593 0.3 0.0\n",
      "37605 0.6 0.0\n",
      "37672 0.65 0.0\n",
      "37688 0.4 0.0\n",
      "37702 0.25 0.0\n",
      "37704 0.95 0.0\n",
      "37710 0.3 0.0\n",
      "37720 0.7 0.0\n",
      "37764 0.75 0.0\n",
      "37773 0.65 0.0\n",
      "37778 0.95 0.0\n",
      "37810 1.0 0.0\n",
      "37816 0.45 0.05\n",
      "37838 0.45 0.1\n",
      "37877 0.25 0.0\n",
      "37932 0.4 0.0\n",
      "37934 0.6 0.0\n",
      "37952 0.6 0.0\n",
      "37962 0.5 0.0\n",
      "38006 0.3 0.0\n",
      "38064 0.95 0.0\n",
      "38082 0.9 0.0\n",
      "38119 0.25 0.0\n",
      "38158 0.9 0.0\n",
      "38182 0.85 0.0\n",
      "38230 0.95 0.0\n",
      "38249 0.55 0.0\n",
      "38271 0.25 0.0\n",
      "38351 0.25 0.0\n",
      "38374 0.4 0.0\n",
      "38382 1.0 0.0\n",
      "38397 0.5 0.0\n",
      "38420 0.6 0.0\n",
      "38510 0.55 0.0\n",
      "38589 0.5 0.0\n",
      "38638 0.35 0.0\n",
      "38673 0.25 0.0\n",
      "38680 0.85 0.1\n",
      "38690 0.85 0.0\n",
      "38760 0.95 0.0\n",
      "38791 0.9 0.0\n",
      "38795 1.0 0.0\n",
      "38832 0.6 0.0\n",
      "38877 0.75 0.0\n",
      "39000 0.35 0.0\n",
      "39172 0.55 0.0\n",
      "39234 0.6 0.0\n",
      "39242 0.25 0.0\n",
      "39266 0.4 0.0\n",
      "39286 0.8 0.0\n",
      "39291 0.45 0.0\n",
      "39293 0.25 0.0\n",
      "39307 1.0 0.05\n",
      "39333 0.25 0.0\n",
      "39351 0.6 0.0\n",
      "39355 0.95 0.05\n",
      "39373 0.95 0.0\n",
      "39377 0.8 0.0\n",
      "39378 0.65 0.05\n",
      "39419 0.95 0.05\n",
      "39425 1.0 0.0\n",
      "39538 0.35 0.0\n",
      "39549 0.25 0.0\n",
      "39576 0.25 0.0\n",
      "39578 0.45 0.0\n",
      "39596 0.7 0.0\n",
      "39598 0.3 0.0\n",
      "39604 0.55 0.0\n",
      "39614 0.25 0.0\n",
      "39640 0.3 0.0\n",
      "39647 0.45 0.0\n",
      "39662 0.25 0.0\n",
      "39668 0.95 0.1\n",
      "39732 0.75 0.0\n",
      "39753 0.5 0.0\n",
      "39764 0.45 0.0\n",
      "39771 0.35 0.0\n",
      "39778 0.75 0.0\n",
      "39779 0.8 0.0\n",
      "39793 0.8 0.0\n",
      "39806 0.3 0.0\n",
      "39822 0.5 0.0\n",
      "39832 1.0 0.0\n",
      "39864 0.9 0.0\n",
      "39873 0.35 0.0\n",
      "39938 0.75 0.0\n",
      "39942 1.0 0.0\n",
      "39951 0.6 0.0\n",
      "39994 0.7 0.0\n",
      "39995 0.45 0.0\n",
      "40012 0.7 0.0\n",
      "40022 1.0 0.0\n",
      "40026 1.0 0.0\n",
      "40092 0.25 0.0\n",
      "40158 0.65 0.0\n",
      "40259 0.5 0.0\n",
      "40264 0.95 0.0\n",
      "40269 0.5 0.0\n",
      "40324 0.45 0.0\n",
      "40364 0.6 0.0\n",
      "40391 0.8 0.0\n",
      "40410 0.75 0.0\n",
      "40437 0.3 0.0\n",
      "40446 0.35 0.0\n",
      "40458 0.3 0.0\n",
      "40466 0.95 0.0\n",
      "40487 0.85 0.0\n",
      "40547 0.9 0.0\n",
      "40558 0.7 0.0\n",
      "40571 0.25 0.0\n",
      "40584 0.3 0.0\n",
      "40646 0.95 0.0\n",
      "40667 0.25 0.0\n",
      "40708 0.55 0.0\n",
      "40781 0.3 0.0\n",
      "40786 0.3 0.0\n",
      "40804 0.4 0.0\n",
      "40882 0.95 0.0\n",
      "40942 0.35 0.0\n",
      "40977 0.65 0.0\n",
      "40978 0.25 0.0\n",
      "41084 0.4 0.0\n",
      "41102 0.75 0.0\n",
      "41124 0.6 0.0\n",
      "41180 0.75 0.0\n",
      "41196 0.95 0.0\n",
      "41199 0.85 0.0\n",
      "41218 0.8 0.0\n",
      "41239 0.35 0.0\n",
      "41254 0.9 0.0\n",
      "41274 0.5 0.0\n",
      "41295 0.85 0.0\n",
      "41302 0.7 0.0\n",
      "41334 1.0 0.0\n",
      "41347 0.6 0.0\n",
      "41349 0.85 0.0\n",
      "41369 0.55 0.0\n",
      "41375 0.65 0.0\n",
      "41377 1.0 0.0\n",
      "41403 0.55 0.0\n",
      "41416 0.6 0.0\n",
      "41434 0.45 0.0\n",
      "41464 0.8 0.05\n",
      "41497 0.75 0.0\n",
      "41501 0.35 0.0\n",
      "41538 0.35 0.05\n",
      "41544 0.25 0.0\n",
      "41562 0.9 0.0\n",
      "41594 0.6 0.05\n",
      "41613 0.5 0.0\n",
      "41622 0.5 0.0\n",
      "41718 0.45 0.0\n",
      "41734 0.55 0.0\n",
      "41738 0.9 0.0\n",
      "41882 1.0 0.0\n",
      "41924 0.6 0.0\n",
      "41948 0.5 0.0\n",
      "41962 0.6 0.0\n",
      "41996 0.45 0.0\n",
      "42020 0.8 0.0\n",
      "42029 1.0 0.0\n",
      "42052 0.85 0.0\n",
      "42059 0.8 0.0\n",
      "42112 0.9 0.1\n",
      "42192 0.3 0.0\n",
      "42222 0.75 0.0\n",
      "42229 0.9 0.15\n",
      "42297 0.75 0.05\n",
      "42306 0.85 0.0\n",
      "42313 0.5 0.0\n",
      "42314 0.75 0.0\n",
      "42344 0.85 0.05\n",
      "42347 0.3 0.0\n",
      "42364 0.95 0.05\n",
      "42365 0.25 0.0\n",
      "42384 0.75 0.0\n",
      "42397 0.4 0.0\n",
      "42437 0.3 0.0\n",
      "42438 1.0 0.0\n",
      "42453 0.45 0.0\n",
      "42482 0.95 0.0\n",
      "42504 0.8 0.0\n",
      "42515 0.75 0.0\n",
      "42557 0.4 0.0\n",
      "42624 0.4 0.05\n",
      "42642 0.45 0.0\n",
      "42645 0.25 0.0\n",
      "42656 0.5 0.0\n",
      "42662 0.5 0.0\n",
      "42665 0.8 0.05\n",
      "42668 0.55 0.0\n",
      "42682 0.75 0.0\n",
      "42688 1.0 0.0\n",
      "42696 0.3 0.0\n",
      "42715 0.4 0.0\n",
      "42757 0.3 0.0\n",
      "42826 0.95 0.0\n",
      "42838 0.95 0.0\n",
      "42860 0.7 0.0\n",
      "42924 0.3 0.0\n",
      "42941 0.9 0.0\n",
      "42943 0.45 0.0\n",
      "42961 0.85 0.0\n",
      "42979 0.95 0.0\n",
      "42987 0.75 0.0\n",
      "42993 0.75 0.0\n",
      "43000 0.3 0.0\n",
      "43001 0.4 0.0\n",
      "43034 1.0 0.0\n",
      "43037 0.9 0.0\n",
      "43042 1.0 0.05\n",
      "43051 0.7 0.0\n",
      "43062 0.6 0.0\n",
      "43069 0.7 0.0\n",
      "43072 0.7 0.0\n",
      "43091 0.5 0.0\n",
      "43096 0.3 0.0\n",
      "43097 0.4 0.0\n",
      "43099 0.7 0.0\n",
      "43107 0.6 0.0\n",
      "43110 0.3 0.0\n",
      "43121 0.5 0.0\n",
      "43174 0.9 0.0\n",
      "43185 0.55 0.0\n",
      "43194 0.75 0.0\n",
      "43207 0.65 0.0\n",
      "43210 0.4 0.0\n",
      "43234 0.5 0.0\n",
      "43242 0.25 0.0\n",
      "43248 1.0 0.0\n",
      "43290 0.5 0.0\n",
      "43310 0.3 0.0\n",
      "43334 0.6 0.0\n",
      "43372 0.95 0.0\n",
      "43385 0.35 0.0\n",
      "43388 0.8 0.0\n",
      "43478 0.4 0.0\n",
      "43504 0.5 0.0\n",
      "43532 0.55 0.0\n",
      "43548 0.9 0.0\n",
      "43588 0.85 0.0\n",
      "43609 0.4 0.0\n",
      "43660 0.85 0.0\n",
      "43745 1.0 0.0\n",
      "43788 0.95 0.0\n",
      "43823 0.95 0.0\n",
      "43864 0.35 0.0\n",
      "43903 0.8 0.0\n",
      "43916 0.7 0.0\n",
      "43930 0.95 0.0\n",
      "43944 0.8 0.0\n",
      "43950 1.0 0.0\n",
      "43953 0.25 0.0\n",
      "43986 1.0 0.0\n",
      "43993 0.3 0.0\n",
      "44002 0.7 0.0\n",
      "44008 0.35 0.0\n",
      "44028 0.55 0.0\n",
      "44043 0.65 0.0\n",
      "44072 0.9 0.0\n",
      "44074 0.25 0.0\n",
      "44081 0.75 0.0\n",
      "44104 0.95 0.0\n",
      "44123 1.0 0.0\n",
      "44172 0.95 0.0\n",
      "44196 1.0 0.0\n",
      "44202 0.85 0.0\n",
      "44223 0.6 0.0\n",
      "44234 0.3 0.0\n",
      "44236 0.4 0.0\n",
      "44261 0.8 0.0\n",
      "44286 0.75 0.0\n",
      "44308 0.45 0.0\n",
      "44328 0.9 0.0\n",
      "44340 1.0 0.0\n",
      "44360 0.35 0.0\n",
      "44442 1.0 0.05\n",
      "44484 0.5 0.0\n",
      "44534 1.0 0.0\n",
      "44618 0.9 0.0\n",
      "44624 0.85 0.0\n",
      "44676 0.55 0.0\n",
      "44702 0.9 0.0\n",
      "44746 0.65 0.0\n",
      "44748 0.8 0.0\n",
      "44759 0.4 0.0\n",
      "44806 0.45 0.0\n",
      "44822 0.55 0.0\n",
      "44839 0.25 0.0\n",
      "44854 1.0 0.0\n",
      "44855 0.45 0.0\n",
      "44878 0.35 0.0\n",
      "44915 0.9 0.0\n",
      "44945 0.35 0.0\n",
      "44961 1.0 0.1\n",
      "44980 0.85 0.0\n",
      "44982 0.6 0.0\n",
      "45019 0.5 0.0\n",
      "45026 0.85 0.0\n",
      "45056 1.0 0.0\n",
      "45057 0.45 0.05\n",
      "45082 0.95 0.0\n",
      "45116 0.75 0.0\n",
      "45117 0.75 0.0\n",
      "45122 0.9 0.0\n",
      "45168 0.75 0.0\n",
      "45201 1.0 0.0\n",
      "45244 0.35 0.0\n",
      "45370 0.25 0.0\n",
      "45427 0.6 0.0\n",
      "45440 0.6 0.0\n",
      "45454 1.0 0.0\n",
      "45458 0.95 0.0\n",
      "45520 0.95 0.0\n",
      "45528 0.25 0.0\n",
      "45529 0.75 0.0\n",
      "45555 0.6 0.0\n",
      "45575 1.0 0.0\n",
      "45576 0.65 0.0\n",
      "45587 0.85 0.0\n",
      "45646 0.6 0.0\n",
      "45653 0.9 0.0\n",
      "45654 0.95 0.0\n",
      "45692 0.9 0.05\n",
      "45706 0.35 0.0\n",
      "45772 0.35 0.0\n",
      "45784 0.95 0.0\n",
      "45787 0.95 0.0\n",
      "45800 0.85 0.0\n",
      "45813 0.3 0.0\n",
      "45824 0.4 0.0\n",
      "45841 0.35 0.0\n",
      "45864 0.85 0.0\n",
      "45868 0.35 0.05\n",
      "45888 0.6 0.1\n",
      "45917 0.9 0.05\n",
      "45944 0.95 0.0\n",
      "45954 1.0 0.0\n",
      "45968 0.9 0.05\n",
      "45980 1.0 0.0\n",
      "45988 0.55 0.0\n",
      "46000 0.35 0.0\n",
      "46021 1.0 0.0\n",
      "46023 0.75 0.0\n",
      "46030 0.25 0.0\n",
      "46066 0.9 0.05\n",
      "46110 0.55 0.0\n",
      "46118 0.85 0.0\n",
      "46146 1.0 0.0\n",
      "46148 0.25 0.0\n",
      "46154 0.55 0.0\n",
      "46161 1.0 0.0\n",
      "46231 0.25 0.0\n",
      "46237 0.45 0.0\n",
      "46243 0.9 0.0\n",
      "46255 0.3 0.0\n",
      "46271 0.8 0.0\n",
      "46284 0.95 0.05\n",
      "46287 0.3 0.0\n",
      "46298 1.0 0.0\n",
      "46308 0.8 0.0\n",
      "46316 0.95 0.1\n",
      "46320 0.85 0.0\n",
      "46336 0.95 0.0\n",
      "46346 0.85 0.0\n",
      "46368 0.95 0.15\n",
      "46373 0.95 0.0\n",
      "46423 0.6 0.0\n",
      "46428 0.25 0.0\n",
      "46435 0.95 0.05\n",
      "46492 0.3 0.0\n",
      "46572 0.25 0.0\n",
      "46573 0.9 0.0\n",
      "46584 0.95 0.0\n",
      "46602 0.65 0.0\n",
      "46616 0.35 0.0\n",
      "46647 0.7 0.0\n",
      "46649 0.45 0.0\n",
      "46658 0.95 0.0\n",
      "46698 0.85 0.0\n",
      "46714 0.9 0.0\n",
      "46776 0.55 0.0\n",
      "46784 0.25 0.0\n",
      "46794 0.3 0.0\n",
      "46828 0.5 0.0\n",
      "46958 0.9 0.0\n",
      "47008 0.95 0.0\n",
      "47056 0.35 0.0\n",
      "47076 0.9 0.0\n",
      "47100 0.85 0.0\n",
      "47152 1.0 0.0\n",
      "47218 0.5 0.0\n",
      "47227 0.9 0.05\n",
      "47237 0.85 0.05\n",
      "47244 0.7 0.0\n",
      "47261 0.9 0.0\n",
      "47264 0.6 0.05\n",
      "47274 1.0 0.0\n",
      "47292 0.4 0.0\n",
      "47297 0.9 0.0\n",
      "47317 0.95 0.0\n",
      "47322 0.5 0.0\n",
      "47387 1.0 0.0\n",
      "47401 0.85 0.0\n",
      "47403 0.85 0.05\n",
      "47420 0.6 0.0\n",
      "47421 0.7 0.05\n",
      "47445 0.95 0.0\n",
      "47456 0.65 0.0\n",
      "47478 0.75 0.0\n",
      "47484 0.5 0.0\n",
      "47498 0.3 0.0\n",
      "47506 0.95 0.0\n",
      "47538 0.9 0.0\n",
      "47540 0.55 0.0\n",
      "47548 0.25 0.0\n",
      "47549 0.25 0.0\n",
      "47597 1.0 0.05\n",
      "47615 0.5 0.0\n",
      "47634 0.55 0.05\n",
      "47662 0.8 0.0\n",
      "47723 0.75 0.0\n",
      "47747 0.25 0.0\n",
      "47762 1.0 0.05\n",
      "47865 0.5 0.0\n",
      "47870 0.8 0.0\n",
      "47882 0.3 0.0\n",
      "47885 0.25 0.0\n",
      "47888 0.95 0.0\n",
      "47918 0.95 0.0\n",
      "47926 0.9 0.05\n",
      "47936 1.0 0.05\n",
      "47958 0.3 0.0\n",
      "48036 0.45 0.0\n",
      "48037 0.45 0.0\n",
      "48042 0.35 0.0\n",
      "48055 0.3 0.0\n",
      "48057 0.4 0.0\n",
      "48060 0.45 0.0\n",
      "48077 0.95 0.0\n",
      "48110 0.8 0.0\n",
      "48115 0.95 0.0\n",
      "48154 0.95 0.0\n",
      "48245 0.5 0.0\n",
      "48272 1.0 0.0\n",
      "48297 0.7 0.0\n",
      "48330 0.8 0.0\n",
      "48344 0.8 0.0\n",
      "48372 0.4 0.0\n",
      "48382 0.95 0.0\n",
      "48384 0.85 0.0\n",
      "48388 0.55 0.0\n",
      "48429 0.35 0.0\n",
      "48475 0.8 0.0\n",
      "48494 0.75 0.0\n",
      "48524 0.95 0.0\n",
      "48540 0.65 0.0\n",
      "48548 0.45 0.0\n",
      "48577 0.35 0.0\n",
      "48584 0.75 0.0\n",
      "48588 0.3 0.0\n",
      "48603 0.75 0.0\n",
      "48618 0.8 0.0\n",
      "48688 0.3 0.0\n",
      "48726 1.0 0.0\n",
      "48750 0.55 0.0\n",
      "48758 0.35 0.0\n",
      "48775 0.25 0.0\n",
      "48802 0.25 0.0\n",
      "48824 0.6 0.0\n",
      "48842 0.3 0.0\n",
      "48938 0.45 0.0\n",
      "48964 0.3 0.0\n",
      "48973 0.65 0.0\n",
      "48997 0.7 0.0\n",
      "49010 0.6 0.0\n",
      "49016 0.35 0.0\n",
      "49064 1.0 0.0\n",
      "49088 0.85 0.1\n",
      "49096 0.9 0.0\n",
      "49121 0.75 0.0\n",
      "49128 0.25 0.0\n",
      "49143 0.7 0.2\n",
      "49213 0.5 0.0\n",
      "49215 0.85 0.0\n",
      "49217 0.25 0.0\n",
      "49226 0.95 0.05\n",
      "49227 0.75 0.0\n",
      "49250 0.9 0.0\n",
      "49276 0.8 0.0\n",
      "49302 0.65 0.0\n",
      "49333 0.45 0.0\n",
      "49438 0.3 0.0\n",
      "49464 0.95 0.0\n",
      "49466 0.85 0.0\n",
      "49487 0.8 0.05\n",
      "49489 0.85 0.0\n",
      "49492 0.3 0.0\n",
      "49493 1.0 0.0\n",
      "49506 0.9 0.0\n",
      "49509 0.8 0.0\n",
      "49511 0.25 0.0\n",
      "49525 0.95 0.0\n",
      "49532 0.35 0.0\n",
      "49541 0.95 0.0\n",
      "49545 0.9 0.0\n",
      "49548 0.75 0.0\n",
      "49549 0.95 0.05\n",
      "49563 0.95 0.0\n",
      "49574 0.8 0.0\n",
      "49578 1.0 0.05\n",
      "49579 0.75 0.0\n",
      "49599 0.45 0.0\n",
      "49634 1.0 0.0\n",
      "49656 1.0 0.0\n",
      "49690 0.9 0.0\n",
      "49740 1.0 0.0\n",
      "49744 0.9 0.0\n",
      "49764 0.75 0.0\n",
      "49804 0.45 0.0\n",
      "49844 0.95 0.0\n",
      "49898 0.4 0.0\n",
      "49904 0.85 0.0\n",
      "49945 0.5 0.0\n",
      "49988 0.35 0.0\n",
      "50054 0.9 0.0\n",
      "50074 0.4 0.0\n",
      "50078 0.9 0.0\n",
      "50088 0.85 0.0\n",
      "50099 0.6 0.0\n",
      "50119 0.25 0.0\n",
      "50144 0.95 0.0\n",
      "50174 0.7 0.0\n",
      "50180 0.75 0.0\n",
      "50186 0.7 0.0\n",
      "50204 0.25 0.0\n",
      "50228 0.8 0.0\n",
      "50246 0.95 0.0\n",
      "50274 0.5 0.0\n",
      "50285 0.45 0.0\n",
      "50306 0.25 0.0\n",
      "50307 0.45 0.0\n",
      "50329 0.8 0.05\n",
      "50342 0.65 0.0\n",
      "50346 0.6 0.0\n",
      "50349 1.0 0.0\n",
      "50373 0.85 0.0\n",
      "50391 0.85 0.0\n",
      "50408 0.5 0.0\n",
      "50410 0.7 0.0\n",
      "50413 0.5 0.0\n",
      "50414 0.95 0.0\n",
      "50462 0.6 0.0\n",
      "50473 0.55 0.0\n",
      "50514 1.0 0.05\n",
      "50522 1.0 0.05\n",
      "50537 0.55 0.0\n",
      "50557 0.4 0.0\n",
      "50578 0.3 0.0\n",
      "50639 0.55 0.0\n",
      "50698 0.85 0.0\n",
      "50714 1.0 0.05\n",
      "50740 0.9 0.0\n",
      "50752 0.3 0.0\n",
      "50767 0.4 0.0\n",
      "50883 0.4 0.0\n",
      "50886 0.3 0.0\n",
      "50896 1.0 0.0\n",
      "50908 0.8 0.0\n",
      "51058 0.35 0.0\n",
      "51104 0.85 0.0\n",
      "51158 0.5 0.0\n",
      "51164 0.55 0.0\n",
      "51194 0.85 0.0\n",
      "51200 0.7 0.0\n",
      "51239 0.3 0.0\n",
      "51240 0.45 0.0\n",
      "51280 0.4 0.05\n",
      "51315 0.9 0.0\n",
      "51394 0.4 0.0\n",
      "51442 0.8 0.1\n",
      "51470 0.5 0.0\n",
      "51576 0.75 0.0\n",
      "51584 0.7 0.0\n",
      "51644 0.9 0.0\n",
      "51730 0.3 0.0\n",
      "51770 0.25 0.0\n",
      "51840 0.3 0.0\n",
      "51863 0.95 0.0\n",
      "51904 0.95 0.0\n",
      "51910 0.85 0.0\n",
      "51964 1.0 0.0\n",
      "52012 0.9 0.0\n",
      "52060 0.8 0.0\n",
      "52091 0.55 0.0\n",
      "52115 0.25 0.0\n",
      "52117 0.45 0.0\n",
      "52138 0.95 0.0\n",
      "52139 0.4 0.0\n",
      "52151 0.45 0.0\n",
      "52180 0.85 0.0\n",
      "52218 0.9 0.05\n",
      "52219 0.9 0.0\n",
      "52232 0.85 0.0\n",
      "52236 0.3 0.0\n",
      "52241 0.55 0.05\n",
      "52270 0.5 0.0\n",
      "52280 0.5 0.05\n",
      "52290 0.4 0.0\n",
      "52306 0.35 0.0\n",
      "52324 0.95 0.05\n",
      "52355 0.35 0.0\n",
      "52390 0.75 0.0\n",
      "52406 0.25 0.0\n",
      "52462 0.25 0.0\n",
      "52465 0.7 0.0\n",
      "52478 0.7 0.0\n",
      "52483 0.3 0.0\n",
      "52510 0.55 0.0\n",
      "52592 0.6 0.0\n",
      "52638 0.5 0.0\n",
      "52646 0.7 0.0\n",
      "52671 0.8 0.0\n",
      "52699 0.85 0.0\n",
      "52718 0.75 0.0\n",
      "52761 0.6 0.0\n",
      "52795 0.55 0.0\n",
      "52800 0.7 0.1\n",
      "52805 0.25 0.0\n",
      "52808 0.5 0.0\n",
      "52814 0.35 0.0\n",
      "52827 0.35 0.0\n",
      "52854 0.25 0.0\n",
      "52862 0.35 0.0\n",
      "52884 0.7 0.0\n",
      "52892 0.9 0.0\n",
      "52910 0.95 0.0\n",
      "52923 0.65 0.0\n",
      "52932 0.3 0.0\n",
      "52968 0.8 0.0\n",
      "53006 0.25 0.0\n",
      "53010 0.25 0.0\n",
      "53028 0.9 0.0\n",
      "53036 0.8 0.0\n",
      "53044 0.8 0.0\n",
      "53055 0.3 0.0\n",
      "53131 0.5 0.0\n",
      "53155 0.5 0.0\n",
      "53170 0.85 0.0\n",
      "53181 0.3 0.0\n",
      "53184 0.25 0.0\n",
      "53190 0.85 0.0\n",
      "53196 0.3 0.0\n",
      "53216 0.5 0.05\n",
      "53248 0.6 0.0\n",
      "53280 0.95 0.0\n",
      "53312 0.95 0.1\n",
      "53324 0.3 0.0\n",
      "53397 0.25 0.0\n",
      "53417 0.4 0.0\n",
      "53462 0.5 0.0\n",
      "53496 0.6 0.0\n",
      "53556 0.4 0.0\n",
      "53574 0.75 0.0\n",
      "53623 1.0 0.0\n",
      "53645 0.55 0.0\n",
      "53653 0.4 0.0\n",
      "53680 0.8 0.1\n",
      "53682 0.75 0.0\n",
      "53700 0.4 0.0\n",
      "53723 0.85 0.0\n",
      "53736 0.8 0.05\n",
      "53784 0.65 0.0\n",
      "53854 0.85 0.0\n",
      "53864 0.25 0.0\n",
      "53872 1.0 0.05\n",
      "53906 0.75 0.0\n",
      "53953 0.4 0.0\n",
      "53976 1.0 0.0\n",
      "53979 0.7 0.0\n",
      "53996 0.55 0.0\n",
      "53997 0.9 0.0\n",
      "53998 0.25 0.0\n",
      "53999 0.8 0.0\n",
      "54026 0.45 0.0\n",
      "54030 0.55 0.0\n",
      "54036 0.9 0.0\n",
      "54038 0.95 0.0\n",
      "54056 0.25 0.0\n",
      "54081 0.7 0.0\n",
      "54146 0.25 0.0\n",
      "54178 0.85 0.0\n",
      "54195 1.0 0.05\n",
      "54362 0.3 0.0\n",
      "54386 0.25 0.0\n",
      "54387 0.85 0.0\n",
      "54394 0.85 0.0\n",
      "54458 0.35 0.05\n",
      "54492 0.9 0.0\n",
      "54520 0.95 0.0\n",
      "54554 1.0 0.0\n",
      "54578 0.3 0.0\n",
      "54586 0.9 0.1\n",
      "54654 0.9 0.0\n",
      "54666 0.85 0.0\n",
      "54850 0.45 0.0\n",
      "54874 0.3 0.0\n",
      "54889 0.8 0.0\n",
      "54896 0.65 0.0\n",
      "54909 0.7 0.0\n",
      "54919 0.35 0.0\n",
      "54926 0.95 0.0\n",
      "54935 0.75 0.0\n",
      "54944 0.5 0.0\n",
      "54950 0.95 0.0\n",
      "54954 0.85 0.0\n",
      "55002 0.35 0.0\n",
      "55015 0.95 0.0\n",
      "55102 0.9 0.0\n",
      "55128 0.7 0.0\n",
      "55153 0.9 0.0\n",
      "55163 0.7 0.0\n",
      "55218 0.7 0.0\n",
      "55263 0.5 0.0\n",
      "55264 0.85 0.0\n",
      "55268 0.95 0.0\n",
      "55296 0.3 0.0\n",
      "55311 0.95 0.0\n",
      "55330 0.85 0.0\n",
      "55368 0.9 0.15\n",
      "55406 1.0 0.0\n",
      "55438 0.9 0.1\n",
      "55496 1.0 0.0\n",
      "55604 1.0 0.0\n",
      "55606 0.85 0.0\n",
      "55612 0.75 0.0\n",
      "55642 0.7 0.0\n",
      "55648 0.25 0.0\n",
      "55696 0.25 0.0\n",
      "55702 0.55 0.0\n",
      "55730 0.95 0.0\n",
      "55762 0.85 0.0\n",
      "55792 1.0 0.0\n",
      "55814 0.95 0.05\n",
      "55834 0.95 0.0\n",
      "55856 0.65 0.0\n",
      "55970 0.95 0.0\n",
      "56001 0.25 0.0\n",
      "56082 0.9 0.0\n",
      "56090 0.95 0.0\n",
      "56118 0.9 0.0\n",
      "56152 0.3 0.0\n",
      "56180 0.4 0.0\n",
      "56199 0.35 0.0\n",
      "56254 0.6 0.0\n",
      "56286 0.35 0.0\n",
      "56292 0.85 0.0\n",
      "56348 0.25 0.0\n",
      "56396 0.7 0.0\n",
      "56412 0.6 0.0\n",
      "56414 0.95 0.0\n",
      "56428 0.25 0.0\n",
      "56443 0.9 0.0\n",
      "56464 0.65 0.0\n",
      "56480 0.95 0.15\n",
      "56494 0.6 0.0\n",
      "56600 0.65 0.0\n",
      "56636 0.5 0.0\n",
      "56667 0.25 0.0\n",
      "56672 0.95 0.0\n",
      "56702 0.75 0.0\n",
      "56708 0.4 0.0\n",
      "56742 0.3 0.0\n",
      "56773 1.0 0.0\n",
      "56774 0.85 0.0\n",
      "56792 0.25 0.0\n",
      "56800 0.9 0.05\n",
      "56839 0.7 0.0\n",
      "56842 0.9 0.0\n",
      "56866 0.85 0.0\n",
      "56978 0.85 0.0\n",
      "56996 0.7 0.0\n",
      "57018 0.45 0.0\n",
      "57021 0.7 0.0\n",
      "57054 0.75 0.0\n",
      "57085 0.3 0.0\n",
      "57100 0.6 0.0\n",
      "57276 0.9 0.1\n",
      "57290 0.25 0.0\n",
      "57404 0.9 0.0\n",
      "57406 0.35 0.0\n",
      "57434 0.65 0.0\n",
      "57452 0.55 0.0\n",
      "57476 0.35 0.0\n",
      "57551 0.25 0.0\n",
      "57665 0.3 0.0\n",
      "57667 0.8 0.0\n",
      "57681 0.4 0.0\n",
      "57683 0.95 0.0\n",
      "57701 0.6 0.0\n",
      "57728 1.0 0.0\n",
      "57729 0.9 0.0\n",
      "57731 0.9 0.0\n",
      "57732 0.95 0.1\n",
      "57737 1.0 0.0\n",
      "57741 0.65 0.0\n",
      "57744 0.55 0.05\n",
      "57786 0.55 0.0\n",
      "57794 0.65 0.0\n",
      "57880 1.0 0.0\n",
      "57898 0.75 0.0\n",
      "58046 0.35 0.0\n",
      "58138 0.45 0.0\n",
      "58187 0.4 0.0\n",
      "58332 0.8 0.0\n",
      "58344 0.9 0.0\n",
      "58384 0.7 0.0\n",
      "58413 0.85 0.0\n",
      "58464 0.5 0.0\n",
      "58470 0.25 0.0\n",
      "58484 0.65 0.0\n",
      "58509 0.25 0.0\n",
      "58518 0.25 0.0\n",
      "58539 0.6 0.0\n",
      "58595 0.5 0.0\n",
      "58692 0.4 0.0\n",
      "58777 0.6 0.0\n",
      "58837 0.45 0.0\n",
      "58961 0.35 0.0\n",
      "59131 0.35 0.0\n",
      "59286 0.9 0.0\n",
      "59294 0.75 0.0\n",
      "59303 0.7 0.0\n",
      "59309 0.5 0.0\n",
      "59314 0.65 0.0\n",
      "59343 0.95 0.0\n",
      "59344 0.4 0.0\n",
      "59361 0.25 0.0\n",
      "59380 0.45 0.0\n",
      "59393 0.55 0.0\n",
      "59395 0.95 0.05\n",
      "59399 0.9 0.0\n",
      "59402 0.4 0.0\n",
      "59423 0.65 0.0\n",
      "59429 0.45 0.0\n",
      "59447 0.7 0.0\n",
      "59449 0.35 0.0\n",
      "59458 0.8 0.0\n",
      "59466 0.35 0.0\n",
      "59636 0.3 0.0\n",
      "59711 0.35 0.0\n",
      "59718 1.0 0.05\n",
      "59719 0.5 0.0\n",
      "59751 0.35 0.0\n",
      "59763 0.45 0.0\n",
      "59899 0.45 0.0\n",
      "59942 0.55 0.0\n",
      "59948 0.4 0.0\n",
      "59969 0.5 0.0\n"
     ]
    }
   ],
   "source": [
    "num_inputs = 60000\n",
    "\n",
    "example_mutant = 'mnist_unbalance_train_data_mutated0_MP_96.88_ki.npy'\n",
    "ki_subsumed = kis_dc[example_mutant]\n",
    "kp_subsumed = np.sum(ki_subsumed, axis=0) / len(ki_subsumed)\n",
    "\n",
    "for subsuming_mutant, _ in g.in_edges(example_mutant):\n",
    "    if subsuming_mutant not in kis_dmpp:\n",
    "        continue\n",
    "\n",
    "    print(\"subsuming: \", subsuming_mutant)\n",
    "    ki_subsuming = kis_dmpp[subsuming_mutant]\n",
    "    kp_subsuming = np.sum(ki_subsuming, axis=0) / len(ki_subsuming)\n",
    "\n",
    "    deleted = unstable_inputs_dict[subsuming_mutant][example_mutant]    \n",
    "    not_deleted = sorted(list(set(range(num_inputs)) - set(deleted)))\n",
    "    for i in not_deleted:        \n",
    "        print(i, kp_subsumed[i], kp_subsuming[i])        \n",
    "    break\n",
    "\n",
    "\n",
    "# for mut1, ki1 in kis_dmpp.items():\n",
    "#     killing_probabilities1 = np.sum(ki1, axis=0) / len(ki1)    \n",
    "\n",
    "#     for mut2, ki2 in kis_dc.items():\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
